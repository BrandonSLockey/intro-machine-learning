<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Dimensionality reduction | An Introduction to Machine Learning</title>
  <meta name="description" content="Course materials for An Introduction to Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Dimensionality reduction | An Introduction to Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figures/cover_image.png" />
  <meta property="og:description" content="Course materials for An Introduction to Machine Learning" />
  <meta name="github-repo" content="bioinformatics-training/intro-machine-learning-2019" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Dimensionality reduction | An Introduction to Machine Learning" />
  
  <meta name="twitter:description" content="Course materials for An Introduction to Machine Learning" />
  <meta name="twitter:image" content="figures/cover_image.png" />

<meta name="author" content="Sudhakaran Prabakaran, Matt Wayland and Chris Penfold" />


<meta name="date" content="2020-10-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="clustering.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About the course</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#overview"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#registration"><i class="fa fa-check"></i><b>1.2</b> Registration</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i><b>1.3</b> Prerequisites</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#github"><i class="fa fa-check"></i><b>1.4</b> Github</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.5</b> License</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#contact"><i class="fa fa-check"></i><b>1.6</b> Contact</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i><b>1.7</b> Colophon</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-is-machine-learning"><i class="fa fa-check"></i><b>2.1</b> What is machine learning?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#aspects-of-ml"><i class="fa fa-check"></i><b>2.2</b> Aspects of ML</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#what-actually-happened-under-the-hood"><i class="fa fa-check"></i><b>2.3</b> What actually happened under the hood</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html"><i class="fa fa-check"></i><b>3</b> Dimensionality reduction</a><ul>
<li class="chapter" data-level="3.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#linear-dimensionality-reduction"><i class="fa fa-check"></i><b>3.1</b> Linear Dimensionality Reduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#interpreting-the-principle-component-axes"><i class="fa fa-check"></i><b>3.1.1</b> Interpreting the Principle Component Axes</a></li>
<li class="chapter" data-level="3.1.2" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#horseshoe-effect"><i class="fa fa-check"></i><b>3.1.2</b> Horseshoe effect</a></li>
<li class="chapter" data-level="3.1.3" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#pca-analysis-of-mammalian-development"><i class="fa fa-check"></i><b>3.1.3</b> PCA analysis of mammalian development</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#exercise-2.3."><i class="fa fa-check"></i><b>3.2</b> Exercise 2.3.</a></li>
<li class="chapter" data-level="3.3" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#nonlinear-dimensionality-reduction"><i class="fa fa-check"></i><b>3.3</b> Nonlinear Dimensionality Reduction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#stochasticity"><i class="fa fa-check"></i><b>3.3.1</b> Stochasticity</a></li>
<li class="chapter" data-level="3.3.2" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#analysis-of-mammalian-development"><i class="fa fa-check"></i><b>3.3.2</b> Analysis of mammalian development</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#other-dimensionality-reduction-techniques"><i class="fa fa-check"></i><b>3.4</b> Other dimensionality reduction techniques</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>4</b> Clustering</a><ul>
<li class="chapter" data-level="4.1" data-path="clustering.html"><a href="clustering.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="clustering.html"><a href="clustering.html#distance-metrics"><i class="fa fa-check"></i><b>4.2</b> Distance metrics</a></li>
<li class="chapter" data-level="4.3" data-path="clustering.html"><a href="clustering.html#hierarchic-agglomerative"><i class="fa fa-check"></i><b>4.3</b> Hierarchic agglomerative</a><ul>
<li class="chapter" data-level="4.3.1" data-path="clustering.html"><a href="clustering.html#linkage-algorithms"><i class="fa fa-check"></i><b>4.3.1</b> Linkage algorithms</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>4.4</b> K-means</a><ul>
<li class="chapter" data-level="4.4.1" data-path="clustering.html"><a href="clustering.html#algorithm"><i class="fa fa-check"></i><b>4.4.1</b> Algorithm</a></li>
<li class="chapter" data-level="4.4.2" data-path="clustering.html"><a href="clustering.html#choosing-initial-cluster-centres"><i class="fa fa-check"></i><b>4.4.2</b> Choosing initial cluster centres</a></li>
<li class="chapter" data-level="4.4.3" data-path="clustering.html"><a href="clustering.html#choosingK"><i class="fa fa-check"></i><b>4.4.3</b> Choosing k</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="clustering.html"><a href="clustering.html#dbscan"><i class="fa fa-check"></i><b>4.5</b> DBSCAN</a><ul>
<li class="chapter" data-level="4.5.1" data-path="clustering.html"><a href="clustering.html#algorithm-1"><i class="fa fa-check"></i><b>4.5.1</b> Algorithm</a></li>
<li class="chapter" data-level="4.5.2" data-path="clustering.html"><a href="clustering.html#implementation-in-r"><i class="fa fa-check"></i><b>4.5.2</b> Implementation in R</a></li>
<li class="chapter" data-level="4.5.3" data-path="clustering.html"><a href="clustering.html#choosing-parameters"><i class="fa fa-check"></i><b>4.5.3</b> Choosing parameters</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="clustering.html"><a href="clustering.html#example-clustering-synthetic-data-sets"><i class="fa fa-check"></i><b>4.6</b> Example: clustering synthetic data sets</a><ul>
<li class="chapter" data-level="4.6.1" data-path="clustering.html"><a href="clustering.html#hierarchic-agglomerative-1"><i class="fa fa-check"></i><b>4.6.1</b> Hierarchic agglomerative</a></li>
<li class="chapter" data-level="4.6.2" data-path="clustering.html"><a href="clustering.html#k-means-1"><i class="fa fa-check"></i><b>4.6.2</b> K-means</a></li>
<li class="chapter" data-level="4.6.3" data-path="clustering.html"><a href="clustering.html#dbscan-1"><i class="fa fa-check"></i><b>4.6.3</b> DBSCAN</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="clustering.html"><a href="clustering.html#evaluating-cluster-quality"><i class="fa fa-check"></i><b>4.7</b> Evaluating cluster quality</a><ul>
<li class="chapter" data-level="4.7.1" data-path="clustering.html"><a href="clustering.html#silhouetteMethod"><i class="fa fa-check"></i><b>4.7.1</b> Silhouette method</a></li>
<li class="chapter" data-level="4.7.2" data-path="clustering.html"><a href="clustering.html#example---k-means-clustering-of-blobs-data-set"><i class="fa fa-check"></i><b>4.7.2</b> Example - k-means clustering of blobs data set</a></li>
<li class="chapter" data-level="4.7.3" data-path="clustering.html"><a href="clustering.html#example---dbscan-clustering-of-noisy-moons"><i class="fa fa-check"></i><b>4.7.3</b> Example - DBSCAN clustering of noisy moons</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="clustering.html"><a href="clustering.html#example-gene-expression-profiling-of-human-tissues"><i class="fa fa-check"></i><b>4.8</b> Example: gene expression profiling of human tissues</a><ul>
<li class="chapter" data-level="4.8.1" data-path="clustering.html"><a href="clustering.html#hierarchic-agglomerative-2"><i class="fa fa-check"></i><b>4.8.1</b> Hierarchic agglomerative</a></li>
<li class="chapter" data-level="4.8.2" data-path="clustering.html"><a href="clustering.html#k-means-2"><i class="fa fa-check"></i><b>4.8.2</b> K-means</a></li>
<li class="chapter" data-level="4.8.3" data-path="clustering.html"><a href="clustering.html#dbscan-2"><i class="fa fa-check"></i><b>4.8.3</b> DBSCAN</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="clustering.html"><a href="clustering.html#exercises"><i class="fa fa-check"></i><b>4.9</b> Exercises</a><ul>
<li class="chapter" data-level="4.9.1" data-path="clustering.html"><a href="clustering.html#clusteringEx1"><i class="fa fa-check"></i><b>4.9.1</b> Exercise 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html"><i class="fa fa-check"></i><b>5</b> Nearest neighbours</a><ul>
<li class="chapter" data-level="5.1" data-path="clustering.html"><a href="clustering.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#classification-simulated-data"><i class="fa fa-check"></i><b>5.2</b> Classification: simulated data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#knn-function"><i class="fa fa-check"></i><b>5.2.1</b> knn function</a></li>
<li class="chapter" data-level="5.2.2" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#plotting-decision-boundaries"><i class="fa fa-check"></i><b>5.2.2</b> Plotting decision boundaries</a></li>
<li class="chapter" data-level="5.2.3" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>5.2.3</b> Bias-variance tradeoff</a></li>
<li class="chapter" data-level="5.2.4" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#choosing-k"><i class="fa fa-check"></i><b>5.2.4</b> Choosing <em>k</em></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#example-on-the-iris-dataset"><i class="fa fa-check"></i><b>5.3</b> Example on the Iris dataset</a></li>
<li class="chapter" data-level="5.4" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#knn-cell-segmentation"><i class="fa fa-check"></i><b>5.4</b> Classification: cell segmentation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#cell-segmentation-data-set"><i class="fa fa-check"></i><b>5.4.1</b> Cell segmentation data set</a></li>
<li class="chapter" data-level="5.4.2" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#data-splitting"><i class="fa fa-check"></i><b>5.4.2</b> Data splitting</a></li>
<li class="chapter" data-level="5.4.3" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#identification-of-data-quality-issues"><i class="fa fa-check"></i><b>5.4.3</b> Identification of data quality issues</a></li>
<li class="chapter" data-level="5.4.4" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#fit-model"><i class="fa fa-check"></i><b>5.4.4</b> Fit model</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#knn-regression"><i class="fa fa-check"></i><b>5.5</b> Regression</a><ul>
<li class="chapter" data-level="5.5.1" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#partition-data"><i class="fa fa-check"></i><b>5.5.1</b> Partition data</a></li>
<li class="chapter" data-level="5.5.2" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#data-pre-processing"><i class="fa fa-check"></i><b>5.5.2</b> Data pre-processing</a></li>
<li class="chapter" data-level="5.5.3" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#search-for-optimum-k"><i class="fa fa-check"></i><b>5.5.3</b> Search for optimum <em>k</em></a></li>
<li class="chapter" data-level="5.5.4" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#use-model-to-make-predictions"><i class="fa fa-check"></i><b>5.5.4</b> Use model to make predictions</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="clustering.html"><a href="clustering.html#exercises"><i class="fa fa-check"></i><b>5.6</b> Exercises</a><ul>
<li class="chapter" data-level="5.6.1" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#knnEx1"><i class="fa fa-check"></i><b>5.6.1</b> Exercise 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>6</b> Support vector machines</a><ul>
<li class="chapter" data-level="6.1" data-path="clustering.html"><a href="clustering.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="svm.html"><a href="svm.html#maximum-margin-classifier"><i class="fa fa-check"></i><b>6.1.1</b> Maximum margin classifier</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="svm.html"><a href="svm.html#support-vector-classifier"><i class="fa fa-check"></i><b>6.2</b> Support vector classifier</a></li>
<li class="chapter" data-level="6.3" data-path="svm.html"><a href="svm.html#support-vector-machine"><i class="fa fa-check"></i><b>6.3</b> Support Vector Machine</a></li>
<li class="chapter" data-level="6.4" data-path="svm.html"><a href="svm.html#example---training-a-classifier"><i class="fa fa-check"></i><b>6.4</b> Example - training a classifier</a><ul>
<li class="chapter" data-level="6.4.1" data-path="svm.html"><a href="svm.html#setup-environment"><i class="fa fa-check"></i><b>6.4.1</b> Setup environment</a></li>
<li class="chapter" data-level="6.4.2" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#partition-data"><i class="fa fa-check"></i><b>6.4.2</b> Partition data</a></li>
<li class="chapter" data-level="6.4.3" data-path="svm.html"><a href="svm.html#visualize-training-data"><i class="fa fa-check"></i><b>6.4.3</b> Visualize training data</a></li>
<li class="chapter" data-level="6.4.4" data-path="svm.html"><a href="svm.html#define-a-custom-model"><i class="fa fa-check"></i><b>6.4.4</b> Define a custom model</a></li>
<li class="chapter" data-level="6.4.5" data-path="svm.html"><a href="svm.html#model-cross-validation-and-tuning"><i class="fa fa-check"></i><b>6.4.5</b> Model cross-validation and tuning</a></li>
<li class="chapter" data-level="6.4.6" data-path="svm.html"><a href="svm.html#prediction-performance-measures"><i class="fa fa-check"></i><b>6.4.6</b> Prediction performance measures</a></li>
<li class="chapter" data-level="6.4.7" data-path="svm.html"><a href="svm.html#plot-decision-boundary"><i class="fa fa-check"></i><b>6.4.7</b> Plot decision boundary</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="svm.html"><a href="svm.html#example---regression"><i class="fa fa-check"></i><b>6.5</b> Example - regression</a></li>
<li class="chapter" data-level="6.6" data-path="svm.html"><a href="svm.html#further-reading"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
<li class="chapter" data-level="6.7" data-path="clustering.html"><a href="clustering.html#exercises"><i class="fa fa-check"></i><b>6.7</b> Exercises</a><ul>
<li class="chapter" data-level="6.7.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>6.7.1</b> Exercise 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>7</b> Decision trees and random forests</a><ul>
<li class="chapter" data-level="7.1" data-path="decision-trees.html"><a href="decision-trees.html#decision-trees-1"><i class="fa fa-check"></i><b>7.1</b> Decision Trees</a></li>
<li class="chapter" data-level="7.2" data-path="decision-trees.html"><a href="decision-trees.html#random-forest"><i class="fa fa-check"></i><b>7.2</b> Random Forest</a></li>
<li class="chapter" data-level="7.3" data-path="clustering.html"><a href="clustering.html#exercises"><i class="fa fa-check"></i><b>7.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="use-case-1.html"><a href="use-case-1.html"><i class="fa fa-check"></i><b>8</b> Use case 1</a><ul>
<li class="chapter" data-level="8.1" data-path="clustering.html"><a href="clustering.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="use-case-1.html"><a href="use-case-1.html#problem-automated-detection-of-malaria"><i class="fa fa-check"></i><b>8.2</b> Problem: automated detection of malaria</a></li>
<li class="chapter" data-level="8.3" data-path="use-case-1.html"><a href="use-case-1.html#challenges"><i class="fa fa-check"></i><b>8.3</b> Challenges</a></li>
<li class="chapter" data-level="8.4" data-path="use-case-1.html"><a href="use-case-1.html#getting-started"><i class="fa fa-check"></i><b>8.4</b> Getting started</a><ul>
<li class="chapter" data-level="8.4.1" data-path="use-case-1.html"><a href="use-case-1.html#load-data"><i class="fa fa-check"></i><b>8.4.1</b> Load data</a></li>
<li class="chapter" data-level="8.4.2" data-path="use-case-1.html"><a href="use-case-1.html#model-comparison"><i class="fa fa-check"></i><b>8.4.2</b> Model comparison</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="use-case-1.html"><a href="use-case-1.html#solutions"><i class="fa fa-check"></i><b>8.5</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>9</b> Linear models and matrix algebra</a><ul>
<li class="chapter" data-level="9.1" data-path="linear-models.html"><a href="linear-models.html#linear-models-1"><i class="fa fa-check"></i><b>9.1</b> Linear models</a></li>
<li class="chapter" data-level="9.2" data-path="linear-models.html"><a href="linear-models.html#matrix-algebra"><i class="fa fa-check"></i><b>9.2</b> Matrix algebra</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Linear regression and logistic regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#regression"><i class="fa fa-check"></i><b>10.1</b> Regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#linear-regression"><i class="fa fa-check"></i><b>10.1.1</b> Linear regression</a></li>
<li class="chapter" data-level="10.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>10.1.2</b> Polynomial regression</a></li>
<li class="chapter" data-level="10.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#distributions-of-fits"><i class="fa fa-check"></i><b>10.1.3</b> Distributions of fits</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#classification"><i class="fa fa-check"></i><b>10.2</b> Classification</a><ul>
<li class="chapter" data-level="10.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression"><i class="fa fa-check"></i><b>10.2.1</b> Logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#resources"><i class="fa fa-check"></i><b>10.3</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ann.html"><a href="ann.html"><i class="fa fa-check"></i><b>11</b> Artificial neural networks</a><ul>
<li class="chapter" data-level="11.1" data-path="ann.html"><a href="ann.html#neural-networks"><i class="fa fa-check"></i><b>11.1</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="use-case-2.html"><a href="use-case-2.html"><i class="fa fa-check"></i><b>12</b> Use case 2</a></li>
<li class="chapter" data-level="13" data-path="mlnn.html"><a href="mlnn.html"><i class="fa fa-check"></i><b>13</b> Deep Learning</a><ul>
<li class="chapter" data-level="13.1" data-path="mlnn.html"><a href="mlnn.html#multilayer-neural-networks"><i class="fa fa-check"></i><b>13.1</b> Multilayer Neural Networks</a><ul>
<li class="chapter" data-level="13.1.1" data-path="mlnn.html"><a href="mlnn.html#reading-in-images"><i class="fa fa-check"></i><b>13.1.1</b> Reading in images</a></li>
<li class="chapter" data-level="13.1.2" data-path="mlnn.html"><a href="mlnn.html#constructing-layers-in-kerasr"><i class="fa fa-check"></i><b>13.1.2</b> Constructing layers in kerasR</a></li>
<li class="chapter" data-level="13.1.3" data-path="mlnn.html"><a href="mlnn.html#rick-and-morty-classifier-using-deep-learning"><i class="fa fa-check"></i><b>13.1.3</b> Rick and Morty classifier using Deep Learning</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="mlnn.html"><a href="mlnn.html#convolutional-neural-networks"><i class="fa fa-check"></i><b>13.2</b> Convolutional neural networks</a><ul>
<li class="chapter" data-level="13.2.1" data-path="mlnn.html"><a href="mlnn.html#checking-the-models"><i class="fa fa-check"></i><b>13.2.1</b> Checking the models</a></li>
<li class="chapter" data-level="13.2.2" data-path="mlnn.html"><a href="mlnn.html#asking-more-precise-questions"><i class="fa fa-check"></i><b>13.2.2</b> Asking more precise questions</a></li>
<li class="chapter" data-level="13.2.3" data-path="mlnn.html"><a href="mlnn.html#more-complex-networks"><i class="fa fa-check"></i><b>13.2.3</b> More complex networks</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="svm.html"><a href="svm.html#further-reading"><i class="fa fa-check"></i><b>13.3</b> Further reading</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="logistic-regression.html"><a href="logistic-regression.html#resources"><i class="fa fa-check"></i><b>A</b> Resources</a><ul>
<li class="chapter" data-level="A.1" data-path="resources.html"><a href="resources.html"><i class="fa fa-check"></i><b>A.1</b> Python</a></li>
<li class="chapter" data-level="A.2" data-path="resources.html"><a href="resources.html#machine-learning-data-set-repositories"><i class="fa fa-check"></i><b>A.2</b> Machine learning data set repositories</a><ul>
<li class="chapter" data-level="A.2.1" data-path="resources.html"><a href="resources.html#mldata"><i class="fa fa-check"></i><b>A.2.1</b> MLDATA</a></li>
<li class="chapter" data-level="A.2.2" data-path="resources.html"><a href="resources.html#uci-machine-learning-repository"><i class="fa fa-check"></i><b>A.2.2</b> UCI Machine Learning Repository</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="solutions-dimensionality-reduction.html"><a href="solutions-dimensionality-reduction.html"><i class="fa fa-check"></i><b>B</b> Solutions ch. 2 - Dimensionality reduction</a><ul>
<li class="chapter" data-level="B.1" data-path="solutions-dimensionality-reduction.html"><a href="solutions-dimensionality-reduction.html#exercise-2.5."><i class="fa fa-check"></i><b>B.1</b> Exercise 2.5.</a></li>
<li class="chapter" data-level="B.2" data-path="solutions-dimensionality-reduction.html"><a href="solutions-dimensionality-reduction.html#exercise-2.6."><i class="fa fa-check"></i><b>B.2</b> Exercise 2.6.</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="solutions-clustering.html"><a href="solutions-clustering.html"><i class="fa fa-check"></i><b>C</b> Solutions ch. 4 - Clustering</a><ul>
<li class="chapter" data-level="C.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>C.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="solutions-nearest-neighbours.html"><a href="solutions-nearest-neighbours.html"><i class="fa fa-check"></i><b>D</b> Solutions ch. 7 - Nearest neighbours</a><ul>
<li class="chapter" data-level="D.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>D.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="solutions-svm.html"><a href="solutions-svm.html"><i class="fa fa-check"></i><b>E</b> Solutions ch. 6 - Support vector machines</a><ul>
<li class="chapter" data-level="E.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>E.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="solutions-decision-trees.html"><a href="solutions-decision-trees.html"><i class="fa fa-check"></i><b>F</b> Solutions ch. 9 - Decision trees and random forests</a><ul>
<li class="chapter" data-level="F.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>F.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html"><i class="fa fa-check"></i><b>G</b> Solutions chapter 8 - use case 1</a><ul>
<li class="chapter" data-level="G.1" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#preparation"><i class="fa fa-check"></i><b>G.1</b> Preparation</a><ul>
<li class="chapter" data-level="G.1.1" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#load-required-libraries"><i class="fa fa-check"></i><b>G.1.1</b> Load required libraries</a></li>
<li class="chapter" data-level="G.1.2" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#define-svm-model"><i class="fa fa-check"></i><b>G.1.2</b> Define SVM model</a></li>
<li class="chapter" data-level="G.1.3" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#setup-parallel-processing"><i class="fa fa-check"></i><b>G.1.3</b> Setup parallel processing</a></li>
<li class="chapter" data-level="G.1.4" data-path="use-case-1.html"><a href="use-case-1.html#load-data"><i class="fa fa-check"></i><b>G.1.4</b> Load data</a></li>
</ul></li>
<li class="chapter" data-level="G.2" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#assess-data-quality"><i class="fa fa-check"></i><b>G.2</b> Assess data quality</a><ul>
<li class="chapter" data-level="G.2.1" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#zero-and-near-zero-variance-predictors"><i class="fa fa-check"></i><b>G.2.1</b> Zero and near-zero variance predictors</a></li>
<li class="chapter" data-level="G.2.2" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#are-all-predictors-on-the-same-scale"><i class="fa fa-check"></i><b>G.2.2</b> Are all predictors on the same scale?</a></li>
<li class="chapter" data-level="G.2.3" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#redundancy-from-correlated-variables"><i class="fa fa-check"></i><b>G.2.3</b> Redundancy from correlated variables</a></li>
<li class="chapter" data-level="G.2.4" data-path="nearest-neighbours.html"><a href="nearest-neighbours.html#skewness"><i class="fa fa-check"></i><b>G.2.4</b> Skewness</a></li>
</ul></li>
<li class="chapter" data-level="G.3" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#infection-status-two-class-problem"><i class="fa fa-check"></i><b>G.3</b> Infection status (two-class problem)</a><ul>
<li class="chapter" data-level="G.3.1" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#model-training-and-parameter-tuning"><i class="fa fa-check"></i><b>G.3.1</b> Model training and parameter tuning</a></li>
<li class="chapter" data-level="G.3.2" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#knn"><i class="fa fa-check"></i><b>G.3.2</b> KNN</a></li>
<li class="chapter" data-level="G.3.3" data-path="svm.html"><a href="svm.html#svm"><i class="fa fa-check"></i><b>G.3.3</b> SVM</a></li>
<li class="chapter" data-level="G.3.4" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#decision-tree"><i class="fa fa-check"></i><b>G.3.4</b> Decision tree</a></li>
<li class="chapter" data-level="G.3.5" data-path="decision-trees.html"><a href="decision-trees.html#random-forest"><i class="fa fa-check"></i><b>G.3.5</b> Random forest</a></li>
<li class="chapter" data-level="G.3.6" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#compare-models"><i class="fa fa-check"></i><b>G.3.6</b> Compare models</a></li>
<li class="chapter" data-level="G.3.7" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#predict-test-set-using-our-best-model"><i class="fa fa-check"></i><b>G.3.7</b> Predict test set using our best model</a></li>
<li class="chapter" data-level="G.3.8" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#roc-curve"><i class="fa fa-check"></i><b>G.3.8</b> ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="G.4" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#discrimination-of-infective-stages-multi-class-problem"><i class="fa fa-check"></i><b>G.4</b> Discrimination of infective stages (multi-class problem)</a><ul>
<li class="chapter" data-level="G.4.1" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#define-cross-validation-procedure"><i class="fa fa-check"></i><b>G.4.1</b> Define cross-validation procedure</a></li>
<li class="chapter" data-level="G.4.2" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#knn-1"><i class="fa fa-check"></i><b>G.4.2</b> KNN</a></li>
<li class="chapter" data-level="G.4.3" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#svm-1"><i class="fa fa-check"></i><b>G.4.3</b> SVM</a></li>
<li class="chapter" data-level="G.4.4" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#decision-tree-1"><i class="fa fa-check"></i><b>G.4.4</b> Decision tree</a></li>
<li class="chapter" data-level="G.4.5" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#random-forest-1"><i class="fa fa-check"></i><b>G.4.5</b> Random forest</a></li>
<li class="chapter" data-level="G.4.6" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#compare-models-1"><i class="fa fa-check"></i><b>G.4.6</b> Compare models</a></li>
<li class="chapter" data-level="G.4.7" data-path="use-case-1-solutions.html"><a href="use-case-1-solutions.html#predict-test-set-using-our-best-model-1"><i class="fa fa-check"></i><b>G.4.7</b> Predict test set using our best model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="H" data-path="solutions-linear-models.html"><a href="solutions-linear-models.html"><i class="fa fa-check"></i><b>H</b> Solutions ch. 3 - Linear models and matrix algebra</a><ul>
<li class="chapter" data-level="H.1" data-path="solutions-linear-models.html"><a href="solutions-linear-models.html#example-2"><i class="fa fa-check"></i><b>H.1</b> Example 2</a></li>
<li class="chapter" data-level="H.2" data-path="solutions-linear-models.html"><a href="solutions-linear-models.html#example-2-1"><i class="fa fa-check"></i><b>H.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="I" data-path="solutions-logistic-regression.html"><a href="solutions-logistic-regression.html"><i class="fa fa-check"></i><b>I</b> Solutions ch. 4 - Linear and non-linear (logistic) regression</a></li>
<li class="chapter" data-level="J" data-path="solutions-ann.html"><a href="solutions-ann.html"><i class="fa fa-check"></i><b>J</b> Solutions ch. 10 - Artificial neural networks</a><ul>
<li class="chapter" data-level="J.1" data-path="svm.html"><a href="svm.html#exercise-1"><i class="fa fa-check"></i><b>J.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="K" data-path="use-case-2-solutions.html"><a href="use-case-2-solutions.html"><i class="fa fa-check"></i><b>K</b> Solutions for use case 2</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dimensionality-reduction" class="section level1">
<h1><span class="header-section-number">3</span> Dimensionality reduction</h1>
<p>In machine learning, dimensionality reduction refers broadly to any modelling approach that reduces the number of variables in a dataset to a few highly informative or representative ones (Figure <a href="#fig:dimreduc"><strong>??</strong></a>). This is necessitated by the fact that large datasets with many variables are inherently difficult for humans to develop a clear intuition for. Dimensionality reduction is therefore an integral step in the analysis of large, complex (biological) datasets, allowing exploratory analyses and more intuitive visualisation that may aid interpretability, as well as forming a chain in the link of more complex analyses.</p>
<div class="figure" style="text-align: center">
<img src="images/swiss_roll_manifold_sculpting.png" alt="Example of a dimensionality reduction. Here we have a two-dimensional dataset embeded in a three-dimensional space (swiss roll dataset)." width="55%" />
<p class="caption">
Example of a dimensionality reduction. Here we have a two-dimensional dataset embeded in a three-dimensional space (swiss roll dataset).
</p>
</div>
<p>In biological applications, systems-level measurements are typically used to decipher complex mechanisms. These include measurements of gene expression from collections of microarrays <span class="citation">(Breeze et al. <a href="#ref-Breeze873">2011</a>,<span class="citation">@windram2012arabidopsis</span>,<span class="citation">@Lewis15</span>,<span class="citation">@Bechtold</span>)</span> or RNA-sequencing experiments <span class="citation">(Irie et al. <a href="#ref-irie2015sox17">2015</a>,<span class="citation">@tang2015unique</span>)</span> that provide quantitative measurments for tens-of-thousands of genes. Studies like these, based on bulk measurements (that is pooled material), provide observations for many variables (in this case many genes) but with relatively few samples e.g., few time points or conditions. The imbalance between the number of variables and the number of observations is referred to as large <em>p</em>, small <em>n</em>, and makes statistical analysis difficult. Dimensionality reduction techniques therefore prove to be a useful first step in any analysis, identifying potential structure that exists in the dataset or highlighting which (combinations of) variables are the most informative.</p>
<p>The increasing prevalence of single cell RNA-sequencing (scRNA-seq) means the scale of datasets has shifted away from large <em>p</em>, small <em>n</em>, towards providing measurements of many variables but with a corresponding large number of observations (large <em>n</em>) albeit from potentially heterogeneous populations. scRNA-sequencing was largely driven by the need to investigate the transcrptomes of cells that were limited in quantity, such as embryonic cells, with early applications in mouse blastomeres <span class="citation">(Tang et al. <a href="#ref-tang2009mrna">2009</a>)</span>. As of 2017, scRNA-seq experiments routinely generate datasets with tens to hundreds-of-thousands of cells (see e.g., <span class="citation">(Svensson, Vento-Tormo, and Teichmann <a href="#ref-svensson2017moore">2017</a>)</span>). Indeed, in 2016, the <a href="https://community.10xgenomics.com/t5/10x-Blog/Our-1-3-million-single-cell-dataset-is-ready-to-download/ba-p/276">10x Genomics million cell experiment</a> provided sequencing for over 1.3 million cells taken from the cortex, hippocampus and ventricular zone of embryonic mice, and large international consortiums, such as the <a href="https://www.humancellatlas.org">Human Cell Atlas</a> aim to create a comprehensive maps of all cell types in the human body. A key goal when dealing with datasets of this magnitude is the identification of subpopulations of cells that may have gone undetected in bulk experiments; another, perhaps more ambitious task, aims to take advantage of any heterogeneity within the population in order to identify a temporal or mechanistic progression of developmental processes or disease.</p>
<p>Of course, whilst dimensionality reduction allows humans to inspect the dataset manually, particularly when the data can be represented in two or three dimensions, we should keep in mind that humans are exceptionally good at identifying patterns in two or three dimensional data, even when no real structure exists (Figure <a href="#fig:humanpattern"><strong>??</strong></a>. It is therefore useful to employ other statistical approaches to search for patterns in the reduced dimensional space. In this sense, dimensionality reduction forms an integral component in the analysis of complex datasets that will typically be combined a variety of machine learning techniques, such as classification, regression, and clustering.</p>
<div class="figure" style="text-align: center">
<img src="images/GB1.jpg" alt="Humans are exceptionally good at identifying patterns in two and three-dimensional spaces - sometimes too good. To illustrate this, note the Great Britain shapped cloud in the image (presumably drifting away from an EU shaped cloud, not shown). More whimsical shaped clouds can also be seen if you have a spare afternoon.  Golcar Matt/Weatherwatchers [BBC News](http://www.bbc.co.uk/news/uk-england-leeds-40287817)" width="35%" />
<p class="caption">
Humans are exceptionally good at identifying patterns in two and three-dimensional spaces - sometimes too good. To illustrate this, note the Great Britain shapped cloud in the image (presumably drifting away from an EU shaped cloud, not shown). More whimsical shaped clouds can also be seen if you have a spare afternoon. Golcar Matt/Weatherwatchers <a href="http://www.bbc.co.uk/news/uk-england-leeds-40287817">BBC News</a>
</p>
</div>
<p>In this chapter we will explore two forms of dimensionality reduction: principle component analysis (<a href="dimensionality-reduction.html#linear-dimensionality-reduction">PCA</a>) and t-distributed stochastic neighbour embedding (<a href="dimensionality-reduction.html#nonlinear-dimensionality-reduction">tSNE</a>), highlighting the advantages and potential pitfalls of each method. As an illustrative example, we will use these approaches to analyse single cell RNA-sequencing data of early human development. Finally, we will illustrate the use of dimensionality redution on an image dataset.</p>
<div id="linear-dimensionality-reduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Linear Dimensionality Reduction</h2>
<p>The most widely used form of dimensionality reduction is principle component analysis (PCA), which was introduced by Pearson in the early 1900’s <span class="citation">(Pearson <a href="#ref-pearson1901liii">1901</a>)</span>, and independently rediscovered by Hotelling <span class="citation">(Hotelling <a href="#ref-hotelling1933analysis">1933</a>)</span>. PCA has a long history of use in biological and ecological applications, with early use in population studies <span class="citation">(Sforza and Edwards <a href="#ref-sforza1964analysis">1964</a>)</span>, and later for the analysis of gene expression data <span class="citation">(Vohradsky, Li, and Thompson <a href="#ref-vohradsky1997identification">1997</a>,<span class="citation">@craig1997developmental</span>,<span class="citation">@hilsenbeck1999statistical</span>)</span>.</p>
<p>PCA is not a dimensionality reduction technique <em>per se</em>, but an alternative way of representing the data that more naturally captures the variance in the system. Specifically, it finds a new co-ordinate system, so that the new “x-axis” (which is called the first principle component; PC1) is aligned along the direction of greatest variance, with an orthogonal “y-axis” aligned along the direction with second greatest variance (the second principle component; PC2), and so forth. At this stage there has been no inherent reduction in the dimensionality of the system, we have simply rotated the data around.</p>
<p>To illustrate PCA we can repeat the analysis of <span class="citation">(Ringnér <a href="#ref-ringner2008principal">2008</a>)</span> using the dataset of <span class="citation">(Saal et al. <a href="#ref-saal2007poor">2007</a>)</span> (GEO GSE5325). This dataset contains gene expression profiles for <span class="math inline">\(105\)</span> breast tumour samples measured using Swegene Human 27K RAP UniGene188 arrays. Within the population of cells, <span class="citation">(Ringnér <a href="#ref-ringner2008principal">2008</a>)</span> focused on the expression of <em>GATA3</em> and <em>XBP1</em>, whose expression was known to correlate with estrogen receptor status [^](Breast cancer cells may be estrogen receptor positive, ER<span class="math inline">\(^+\)</span>, or negative, ER<span class="math inline">\(^-\)</span>, indicating capacity to respond to estrogen signalling, which has impliations for treatment), representing a two dimensional system. A pre-processed dataset containing the expression levels for <em>GATA3</em> and <em>XBP1</em>, and ER status, can be loaded into R using the code, below:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">D &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file =</span> <span class="st">&quot;data/GSE5325/GSE5325_markers.csv&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">row.names=</span><span class="dv">1</span>)</a></code></pre></div>
<p>For illustration purposes we’ve also included 3 additional variables that have been generated as independent random samples from a univariate normal distribution. We thus have a a <span class="math inline">\(5\)</span> dimensional system, with <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> representing the expression levels of <em>GATA3</em> and <em>XBP1</em> (rows 1 and 2). For convenience we also have the ER status, which we will not use directly, but simply as a visual readout of our appraoch. We start by plotting <em>GATA3</em> expression versus <em>XBP1</em>, and color by ER status:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">plot</span>(<span class="kw">t</span>(D[<span class="dv">1</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">0</span>)]),<span class="kw">t</span>(D[<span class="dv">2</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">0</span>)]),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">ylab=</span><span class="st">&quot;XBP1&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;GATA3&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="kw">min</span>(D[<span class="dv">2</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="kw">max</span>(D[<span class="dv">2</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>)),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="kw">min</span>(D[<span class="dv">1</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="kw">max</span>(D[<span class="dv">1</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>)))</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="kw">points</span>(<span class="kw">t</span>(D[<span class="dv">1</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">1</span>)]),<span class="kw">t</span>(D[<span class="dv">2</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">1</span>)]),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>As this system is inherently low dimensional we can clearly see that ER status correlates with both <em>GATA3</em> and <em>XBP1</em> expression. We perform PCA in R using the  function. To do so, we first filter out datapoints that have missing observations, as PCA does not, inherently, deal with missing observations. We will now run PCA using just the first two dimensions to understand what’s going on:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">Dommitsamps &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">na.omit</span>(<span class="kw">t</span>(D[,]))); <span class="co">#Get the subset of samples</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"></a>
<a class="sourceLine" id="cb3-3" data-line-number="3">pca1  &lt;-<span class="st"> </span><span class="kw">prcomp</span>(<span class="kw">t</span>(Dommitsamps[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,]), <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">ERexp &lt;-<span class="st"> </span>Dommitsamps[<span class="dv">6</span>,];</a>
<a class="sourceLine" id="cb3-5" data-line-number="5"></a>
<a class="sourceLine" id="cb3-6" data-line-number="6">ER_neg &lt;-<span class="st"> </span>pca1<span class="op">$</span>x[<span class="kw">which</span>(ERexp<span class="op">==</span><span class="dv">0</span>),]</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">ER_pos &lt;-<span class="st"> </span>pca1<span class="op">$</span>x[<span class="kw">which</span>(ERexp<span class="op">==</span><span class="dv">1</span>),]</a>
<a class="sourceLine" id="cb3-8" data-line-number="8"></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="kw">plot</span>(ER_neg[,<span class="dv">1</span>],ER_neg[,<span class="dv">2</span>],<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;PC2&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">4.2</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="fl">2.5</span>))</a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="kw">points</span>(ER_pos[,<span class="dv">1</span>],ER_pos[,<span class="dv">2</span>],<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Note that the  has the option to centre and scale the data. That is, to normalise each variable to have a zero-mean and unit variance. This is particularly important when dealing with variables that may exist over very different scales. For example, for ecological datasets we may have variables that were measured in seconds with others measured in hours. Without normalisation there would appear to be much greater variance in the variable measured in seconds, potentially skewing the results. In general, when dealing with variables that are measured on similar scales (for example gene expression) it is not desirable to normalise the data.</p>
<p>We can better visualise what the PCA has done by plotting the original data side-by-side with the transformed data (note that here we have plotted the negative of PC1).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="kw">plot</span>(<span class="kw">t</span>(D[<span class="dv">1</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">0</span>)]),<span class="kw">t</span>(D[<span class="dv">2</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">0</span>)]),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">ylab=</span><span class="st">&quot;XBP1&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;GATA3&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="kw">min</span>(D[<span class="dv">2</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="kw">max</span>(D[<span class="dv">2</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>)),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="kw">min</span>(D[<span class="dv">1</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="kw">max</span>(D[<span class="dv">1</span>,],<span class="dt">na.rm =</span> <span class="ot">TRUE</span>)))</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="kw">points</span>(<span class="kw">t</span>(D[<span class="dv">1</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">1</span>)]),<span class="kw">t</span>(D[<span class="dv">2</span>,<span class="kw">which</span>(D[<span class="dv">6</span>,]<span class="op">==</span><span class="dv">1</span>)]),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="kw">plot</span>(<span class="op">-</span>ER_neg[,<span class="dv">1</span>],ER_neg[,<span class="dv">2</span>],<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;-PC1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;PC2&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">4.2</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="fl">2.5</span>))</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="kw">points</span>(<span class="op">-</span>ER_pos[,<span class="dv">1</span>],ER_pos[,<span class="dv">2</span>],<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>We can seen that we have simply rotated the original data, so that the greatest variance aligns along the x-axis and so forth. We can find out how much of the variance each of the principle components explains by looking at \texttt{pca1$sdev}:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="kw">barplot</span>(((pca1<span class="op">$</span>sdev)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(pca1<span class="op">$</span>sdev<span class="op">^</span><span class="dv">2</span>))<span class="op">*</span><span class="dv">100</span>, <span class="dt">names.arg=</span><span class="kw">c</span>(<span class="st">&quot;PC1&quot;</span>,<span class="st">&quot;PC2&quot;</span>), <span class="dt">ylab=</span><span class="st">&quot;% variance&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>PC1 explains the vast majority of the variance in the observations. The dimensionality reduction step of PCA occurs when we choose to discard the higher PCs. Of course, by doing so we loose some information about the system, but this may be an acceptable loss compared to the increased interpretability achieved by visualising the system in lower dimensions. In the example from <span class="citation">(Ringnér <a href="#ref-ringner2008principal">2008</a>)</span> we can visualise the data using only PC1.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw">plot</span>(<span class="op">-</span>ER_neg[,<span class="dv">1</span>],<span class="kw">matrix</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="kw">length</span>(ER_neg[,<span class="dv">1</span>])),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;PC1&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">3</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">1.5</span>,<span class="fl">1.5</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="kw">points</span>(<span class="op">-</span>ER_pos[,<span class="dv">1</span>],<span class="kw">matrix</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="kw">length</span>(ER_pos[,<span class="dv">1</span>])),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="kw">points</span>(<span class="op">-</span>ER_neg[,<span class="dv">1</span>],<span class="kw">matrix</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="kw">length</span>(ER_neg[,<span class="dv">1</span>])),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;PC1&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">3</span>))</a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="kw">points</span>(<span class="op">-</span>ER_pos[,<span class="dv">1</span>],<span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="kw">length</span>(ER_pos[,<span class="dv">1</span>])),<span class="st">&#39;p&#39;</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">2</span>, <span class="dt">at =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">by =</span> <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;All&quot;</span>,<span class="st">&quot;ER-&quot;</span>,<span class="st">&quot;ER+&quot;</span>))</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>So reducing the system down to one dimension appears to have done a good job at separating out the ER<span class="math inline">\(^+\)</span> cells from the ER<span class="math inline">\(^-\)</span> cells, suggesting that it may be of biological use. Precisely how many PCs to retain remains subjective. For visualisation purposed, it is typical to look at the first two or three only. However, when using PCA as an intermediate step within more complex workflows, more PCs are often retained e.g., by thresholding to a suitable level of explanatory variance.</p>
<div id="interpreting-the-principle-component-axes" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Interpreting the Principle Component Axes</h3>
<p>In the original data, the individual axes had very obvious interpretations: the x-axis represented expression levels of <em>GATA3</em> and the y-axis represented the expression level of <em>XBP1</em>. Other than indicating maximum variance, what does PC1 mean? The individual axes represent linear combinations of the expression of various genes. This may not be immediately intuitive, but we can get a feel by projecting the original axes (gene expression) onto the (reduced dimensional) co-ordinate system.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">genenames &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;GATA3&quot;</span>,<span class="st">&quot;XBP1&quot;</span>)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw">plot</span>(<span class="op">-</span>pca1<span class="op">$</span>rotation[,<span class="dv">1</span>],pca1<span class="op">$</span>rotation[,<span class="dv">2</span>], <span class="dt">type=</span><span class="st">&quot;n&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;PC2&quot;</span>)</a>
<a class="sourceLine" id="cb7-3" data-line-number="3"><span class="kw">text</span>(<span class="op">-</span>pca1<span class="op">$</span>rotation[,<span class="dv">1</span>], pca1<span class="op">$</span>rotation[,<span class="dv">2</span>], genenames, <span class="dt">cex =</span> <span class="fl">.4</span>)</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="kw">arrows</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dt">x1 =</span> <span class="op">-</span>pca1<span class="op">$</span>rotation[,<span class="dv">1</span>], <span class="dt">y1 =</span> <span class="op">-</span>pca1<span class="op">$</span>rotation[,<span class="dv">2</span>],<span class="dt">length=</span><span class="fl">0.1</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>In this particular case, we can see that both genes appear to be reasonably strongly associated with PC1. When dealing with much larger systems e.g., with more genes, we can, of course, project the original axes into the reduced dimensional space. In general this is particularly useful for identifying genes associated with particular PCs, and ultimately assigning a biological interpretation to the PCs.</p>
<p>Excercise: Try doing a PCA again, this time including all variables. What are the key features of the dataset?</p>
</div>
<div id="horseshoe-effect" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Horseshoe effect</h3>
<p>Principle component analysis is a linear dimensionality reduction technique, and is not always appropriate for complex datasets, particularly when dealing with nonlinearities. To illustrate this, let’s consider an simulated expression set containing <span class="math inline">\(8\)</span> genes, with <span class="math inline">\(10\)</span> timepoints/conditions. We can represent this dataset in terms of a matrix:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">X &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">                 <span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,  </a>
<a class="sourceLine" id="cb8-4" data-line-number="4">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,   </a>
<a class="sourceLine" id="cb8-5" data-line-number="5">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,    </a>
<a class="sourceLine" id="cb8-6" data-line-number="6">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,   </a>
<a class="sourceLine" id="cb8-7" data-line-number="7">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>,  </a>
<a class="sourceLine" id="cb8-8" data-line-number="8">                 <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>), <span class="dt">nrow=</span><span class="dv">8</span>,  <span class="dt">ncol=</span><span class="dv">10</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p>Or we can visualise by plotting a few of the genes:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,X[<span class="dv">1</span>,],<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">14</span>),<span class="dt">xlab=</span><span class="st">&quot;Time&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Expression&quot;</span>)</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="kw">points</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,X[<span class="dv">2</span>,],<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="kw">points</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,X[<span class="dv">5</span>,],<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="kw">legend</span>(<span class="dv">8</span>, <span class="dv">4</span>, <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;gene 1&quot;</span>, <span class="st">&quot;gene 2&quot;</span>, <span class="st">&quot;gene 5&quot;</span>), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;black&quot;</span>),<span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>By eye, we see that the data can be separated out by a single direction: that is, we can order the data from time/condition 1 through to time/condition 10. Intuitively, then, the data can be represented by a single dimension. Let’s run PCA as we would normally, and visualise the result, plotting the first two PCs:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">pca2 &lt;-<span class="st"> </span><span class="kw">prcomp</span>((X),<span class="dt">center =</span> <span class="ot">TRUE</span>,<span class="dt">scale=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">condnames =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;G1&#39;</span>,<span class="st">&#39;G2&#39;</span>,<span class="st">&#39;G3&#39;</span>,<span class="st">&#39;G4&#39;</span>,<span class="st">&#39;G5&#39;</span>,<span class="st">&#39;G6&#39;</span>,<span class="st">&#39;G7&#39;</span>,<span class="st">&#39;G8&#39;</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="kw">plot</span>(pca2<span class="op">$</span>x[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="kw">text</span>(pca2<span class="op">$</span>x[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]<span class="op">+</span><span class="fl">0.5</span>, condnames, <span class="dt">cex =</span> <span class="fl">0.7</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>We see that the PCA plot has placed the datapoints in a horseshoe shape, with gene 1 becoming closer to gene 8. From the earlier plots of gene expression profiles we can see that the relationships between the various genes are not entirely straightforward. For example, gene 1 is initially correlated with gene 2, then negatively correlated, and finally uncorrelated, whilst no correlation exists between gene 1 and genes 5 - 8. These nonlinearities make it difficult for PCA which, in general, attempts to preserve large pairwise distances, leading to the well known horseshoe effect <span class="citation">(Novembre and Stephens <a href="#ref-novembre2008interpreting">2008</a>,<span class="citation">@reich2008principal</span>)</span>. These types of artefacts may be problematic when trying to interpret data, and due care must be given when these type of effects are seen.</p>
</div>
<div id="pca-analysis-of-mammalian-development" class="section level3">
<h3><span class="header-section-number">3.1.3</span> PCA analysis of mammalian development</h3>
<p>Now that we have a feel for PCA and understand some of the basic commands we can apply it in a real setting. Here we will make use of preprocessed data taken from <span class="citation">(Yan et al. <a href="#ref-yan2013single">2013</a>)</span> (GEO GSE36552) and <span class="citation">(Guo et al. <a href="#ref-guo2015transcriptome">2015</a>)</span> (GEO GSE63818). The data from <span class="citation">(Yan et al. <a href="#ref-yan2013single">2013</a>)</span> represents single cell RNA-seq measurements from human embryos from the zygote stage (a single cell produced following fertilisation of an egg) through to the blastocyst stage (an embryo consisting of around 64 cells), as well as human embryonic stem cells (hESC; cells extracted from an early blsatocyst stage embryo and maintained <em>in vitro</em>). The dataset of <span class="citation">(Guo et al. <a href="#ref-guo2015transcriptome">2015</a>)</span> contains scRNA-seq data from human primordial germ cells (hPGCs), precursors of sperm or eggs that are specified early in the developing human embryo soon after implantation (around week 2-3 in humans), and somatic cells. Together, these datasets provide useful insights into early human development, and possible mechanisms for the specification of early cell types, such as PGCs.</p>
<div class="figure" style="text-align: center">
<img src="images/PGCs.png" alt="Example of early human development. Here we have measurements of cells from preimplantation embryos, embryonic stem cells, and from post-implantation primordial germ cells and somatic tissues." width="55%" />
<p class="caption">
Example of early human development. Here we have measurements of cells from preimplantation embryos, embryonic stem cells, and from post-implantation primordial germ cells and somatic tissues.
</p>
</div>
<p>Preprocessed data contains <span class="math inline">\(\log_2\)</span> normalised counts for around <span class="math inline">\(400\)</span> cells using <span class="math inline">\(2957\)</span> marker genes can be found in the file \texttt{/data/PGC_transcriptomics/PGC_transcriptomics.csv}. Note that the first line of data in the file is an indicator denoting cell type (-1 = ESC, 0 = pre-implantation, 1 = PGC, and 2 = somatic cell). The second row indicates the sex of the cell (0 = unknown/unlabelled, 1 = XX, 2 = XY), with the third row indicating capture time (-1 = ESC, 0 - 7 denotes various developmental stages from zygote to blastocyst, 8 - 13 indicates increasing times of embryo development from week 4 through to week 19).</p>
<p>We will first run PCA on the data. Recall that the data is already log_2 normalised, with expression values beginning from row 4. Within R we would run:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">12345</span>)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">D &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file =</span> <span class="st">&quot;data/PGC_transcriptomics/PGC_transcriptomics.csv&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">row.names=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">genenames &lt;-<span class="st"> </span><span class="kw">rownames</span>(D)</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">genenames &lt;-<span class="st"> </span>genenames[<span class="dv">4</span><span class="op">:</span><span class="kw">nrow</span>(D)]</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">pcaresult &lt;-<span class="st"> </span><span class="kw">prcomp</span>(<span class="kw">t</span>(D[<span class="dv">4</span><span class="op">:</span><span class="kw">nrow</span>(D),<span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(D)]), <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Here we have opted to centre the data, but have not normalised each gene to be zero-mean. This is beacuse we are dealing entirely with gene expression, rather than a variety of variables that may exist on different scales.</p>
<p>We can extract the positions of individual cells from the \texttt{pcaresult$x} variable. In the snippet, below, we index the different cells types (ESC, pre-implantation cells, primordial germ cells and somatic cells) for easier plotting.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">y1 &lt;-<span class="st"> </span>pcaresult<span class="op">$</span>x[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==-</span><span class="dv">1</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="co"># PCA</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2">y2 &lt;-<span class="st"> </span>pcaresult<span class="op">$</span>x[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">0</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]  <span class="co">#</span></a>
<a class="sourceLine" id="cb12-3" data-line-number="3">y3 &lt;-<span class="st"> </span>pcaresult<span class="op">$</span>x[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">1</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]  <span class="co">#</span></a>
<a class="sourceLine" id="cb12-4" data-line-number="4">y4 &lt;-<span class="st"> </span>pcaresult<span class="op">$</span>x[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">2</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]  <span class="co">#</span></a></code></pre></div>
<p>Finally, we can plot the data as follows:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">plot</span>(y1,<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">50</span>, <span class="dv">50</span>))</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="kw">points</span>(y2,<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="kw">points</span>(y3,<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="kw">points</span>(y4,<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;green&quot;</span>)</a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="kw">legend</span>(<span class="op">-</span><span class="dv">95</span>, <span class="dv">50</span>, <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;ESC&quot;</span>, <span class="st">&quot;preimp&quot;</span>, <span class="st">&quot;PGC&quot;</span>, <span class="st">&quot;soma&quot;</span>), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>), <span class="dt">pch=</span><span class="st">&quot;o&quot;</span>, <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>From the plot, we can see PCA has done a reasonable job of separating out various cells. For example, a cluster of PGCs appears at the top of the plot, with somatic cells towards the lower right hand side. Pre-implantation embryos and ESCs appear to cluster together: perhaps this is not surprising as ESCs are derived from blastocyst cells. Loosely, we can interpret PC1 as dividing pre-implantation cells from somatic cells, with PC2 separating out PGCs.</p>
<p>Previously we used PCA to reduce the dimensionality of our data from thousands of genes down to two principle components. By eye, PCA appeared to do a reasonable job separating out different cell types. A useful next step might therefore be to perform clustering on the reduced dimensional space. We will go into more details about clusterin in subsequent sections, but for now we will simply use clustering as a tool for seperating out our datasets. We can run k-means clustering on a matrix using:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">clust &lt;-<span class="st"> </span><span class="kw">kmeans</span>(pcaresult<span class="op">$</span>x[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dv">4</span>, <span class="dt">iter.max =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>We can now compare the cluster assignment to the known cell types:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">Labels &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;character&quot;</span>, <span class="kw">ncol</span>(D))</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">Labels[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==-</span><span class="dv">1</span>)] =<span class="st"> &quot;ESC&quot;</span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3">Labels[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">0</span>)] =<span class="st"> &quot;preimp&quot;</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4">Labels[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">1</span>)] =<span class="st"> &quot;PGC&quot;</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5">Labels[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==</span><span class="dv">2</span>)] =<span class="st"> &quot;soma&quot;</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"></a>
<a class="sourceLine" id="cb15-7" data-line-number="7">clusterresults &lt;-<span class="st"> </span><span class="kw">rbind</span>(Labels,clust<span class="op">$</span>cluster)</a></code></pre></div>
<p>We note that, in general PGCs fall into one or more separate clusters, with soma also separating out well. ESCs and pre-implantation tend to fall into identical clusters. We can take a look at what cell types fall into a specific cluster:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">clusterresults[<span class="dv">1</span>,<span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">1</span>)]</a></code></pre></div>
<pre><code>##     PGC   PGC.1   PGC.2   PGC.3   PGC.4   PGC.5   PGC.6   PGC.7   PGC.8   PGC.9 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.10  PGC.11  PGC.12  PGC.13  PGC.14  PGC.15  PGC.16  PGC.17  PGC.18  PGC.19 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.20  PGC.21  PGC.22  PGC.23  PGC.24  PGC.25  PGC.26  PGC.27  PGC.28  PGC.29 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.30  PGC.31  PGC.32  PGC.33  PGC.34  PGC.35  PGC.36  PGC.37  PGC.38  PGC.39 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.40  PGC.41  PGC.42  PGC.43  PGC.44  PGC.45  PGC.46  PGC.47  PGC.48  PGC.49 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.50  PGC.51  PGC.52  PGC.53  PGC.54  PGC.55  PGC.56  PGC.57  PGC.58  PGC.59 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.60  PGC.61  PGC.62  PGC.63  PGC.64  PGC.65  PGC.66  PGC.67  PGC.68  PGC.69 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.70  PGC.71  PGC.72  PGC.73  PGC.74  PGC.75  PGC.76  PGC.77  PGC.78  PGC.79 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.80  PGC.81  PGC.82  PGC.83  PGC.84  PGC.85  PGC.86  PGC.87  PGC.88  PGC.89 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
##  PGC.90  PGC.91  PGC.92  PGC.93  PGC.94  PGC.95  PGC.96  PGC.97  PGC.98  PGC.99 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.100 PGC.101 PGC.102 PGC.103 PGC.104 PGC.105 PGC.106 PGC.107 PGC.108 PGC.110 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.112 PGC.113 PGC.114 PGC.115 PGC.116 PGC.117 PGC.118 PGC.119 PGC.120 PGC.121 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.122 PGC.123 PGC.124 PGC.125 PGC.126 PGC.127 PGC.128 PGC.129 PGC.130 PGC.131 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.132 PGC.133 PGC.134 PGC.135 PGC.136 PGC.137 PGC.138 PGC.139 PGC.140 PGC.141 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.142 PGC.143 PGC.146 PGC.147 PGC.148 PGC.149 PGC.150 PGC.151 PGC.152 PGC.153 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.154 PGC.155 PGC.156 PGC.157 PGC.158 PGC.159 PGC.160 PGC.161 PGC.162 PGC.163 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.164 PGC.165 PGC.166 PGC.167 PGC.168 PGC.169 PGC.170 PGC.171 PGC.172 PGC.173 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.174 PGC.175 PGC.176 PGC.177 PGC.178 PGC.179 PGC.180 PGC.181 PGC.182 PGC.183 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.184 PGC.185 PGC.186 PGC.187 PGC.188 PGC.189 PGC.190 PGC.191 PGC.195 PGC.198 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.205 PGC.207 PGC.217 PGC.233 PGC.234 PGC.235 PGC.236 PGC.237 PGC.238 PGC.239 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.240 PGC.241 
##   &quot;PGC&quot;   &quot;PGC&quot;</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">clusterresults[<span class="dv">1</span>,<span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">2</span>)]</a></code></pre></div>
<pre><code>##    preimp  preimp.1  preimp.2  preimp.3  preimp.4  preimp.5  preimp.6  preimp.7 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
##  preimp.8  preimp.9 preimp.10 preimp.11       ESC     ESC.1 preimp.12 preimp.13 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;     &quot;ESC&quot;     &quot;ESC&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.14 preimp.15 preimp.16 preimp.17 preimp.18 preimp.19 preimp.20 preimp.21 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.22 preimp.23 preimp.24 preimp.25 preimp.26 preimp.27 preimp.28 preimp.29 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.30 preimp.31 preimp.32 preimp.33 preimp.34 preimp.35 preimp.36 preimp.37 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.38 preimp.39 preimp.40 preimp.41 preimp.42 preimp.43 preimp.44 preimp.45 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.46 preimp.47 preimp.48 preimp.49 preimp.50 preimp.52 preimp.53 preimp.54 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.55 preimp.56 preimp.57 preimp.58 preimp.59 preimp.60 preimp.61 preimp.62 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.63 preimp.64 preimp.65 preimp.66 preimp.67 preimp.68 preimp.69 preimp.70 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.71 preimp.72 preimp.73 preimp.74 preimp.75 preimp.76 preimp.77 preimp.78 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.79 preimp.80 preimp.81 preimp.82 preimp.83 preimp.84 preimp.85 preimp.86 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot; 
## preimp.87 preimp.88 preimp.89     ESC.2     ESC.3     ESC.4     ESC.5     ESC.6 
##  &quot;preimp&quot;  &quot;preimp&quot;  &quot;preimp&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot; 
##     ESC.7     ESC.8     ESC.9    ESC.10    ESC.11    ESC.12    ESC.13    ESC.14 
##     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot; 
##    ESC.15    ESC.16    ESC.17    ESC.18    ESC.19    ESC.20    ESC.21    ESC.22 
##     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot; 
##    ESC.23    ESC.24    ESC.25    ESC.26    ESC.27    ESC.28    ESC.29    ESC.30 
##     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot;     &quot;ESC&quot; 
##    ESC.32    ESC.33   soma.48   soma.49   soma.51   soma.52 
##     &quot;ESC&quot;     &quot;ESC&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">clusterresults[<span class="dv">1</span>,<span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">3</span>)]</a></code></pre></div>
<pre><code>## preimp.51    ESC.31   PGC.192   PGC.193   PGC.194   PGC.196   PGC.197   PGC.199 
##  &quot;preimp&quot;     &quot;ESC&quot;     &quot;PGC&quot;     &quot;PGC&quot;     &quot;PGC&quot;     &quot;PGC&quot;     &quot;PGC&quot;     &quot;PGC&quot; 
##   PGC.200   PGC.201      soma    soma.1    soma.2    soma.3    soma.4    soma.5 
##     &quot;PGC&quot;     &quot;PGC&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##    soma.6    soma.7    soma.8    soma.9   soma.10   soma.11   soma.12   soma.13 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.14   soma.15   soma.16   soma.17   soma.18   soma.19   soma.20   soma.21 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.22   soma.23   soma.24   soma.25   soma.26   soma.27   soma.28   soma.29 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.30   soma.31   soma.32   soma.33   soma.34   soma.35   soma.36   soma.37 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.38   soma.39   soma.40   soma.41   soma.42   soma.43   soma.44   soma.45 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.46   soma.47   soma.50   soma.53   soma.54   soma.55   soma.56   soma.57 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.58   soma.59   soma.60   soma.61   soma.62   soma.63   soma.64   soma.65 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.66   soma.67   soma.68   soma.69   soma.70   soma.71   soma.72   soma.73 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.74   soma.75   soma.76   soma.77   soma.78   soma.79   soma.80   soma.81 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot; 
##   soma.82   soma.83   soma.84   soma.85 
##    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;    &quot;soma&quot;</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">clusterresults[<span class="dv">1</span>,<span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">4</span>)]</a></code></pre></div>
<pre><code>## PGC.109 PGC.111 PGC.144 PGC.145 PGC.202 PGC.203 PGC.204 PGC.206 PGC.208 PGC.209 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.210 PGC.211 PGC.212 PGC.213 PGC.214 PGC.215 PGC.216 PGC.218 PGC.219 PGC.220 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.221 PGC.222 PGC.223 PGC.224 PGC.225 PGC.226 PGC.227 PGC.228 PGC.229 PGC.230 
##   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot;   &quot;PGC&quot; 
## PGC.231 PGC.232 
##   &quot;PGC&quot;   &quot;PGC&quot;</code></pre>
</div>
</div>
<div id="exercise-2.3." class="section level2">
<h2><span class="header-section-number">3.2</span> Exercise 2.3.</h2>
<p>In our previous section we identified clusters associated with various groups. In our application cluster 1 was associated primarily with pre-implantation cells, with cluster 3 associated with PGCs. We could therefore empirically look for genes that are differentially expressed. Since we know SOX17 is associated with PGC specification in humans <span class="citation">(Irie et al. <a href="#ref-irie2015sox17">2015</a>,<span class="citation">@tang2015unique</span>)</span> let’s first compare the expression levels of SOX17 in the two groups:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="kw">t.test</span>(D[<span class="kw">which</span>(genenames<span class="op">==</span><span class="st">&quot;SOX17&quot;</span>)<span class="op">+</span><span class="dv">3</span>, <span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">1</span>)],D[<span class="kw">which</span>(genenames<span class="op">==</span><span class="st">&quot;SOX17&quot;</span>)<span class="op">+</span><span class="dv">3</span>, <span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">3</span>)])</a></code></pre></div>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  D[which(genenames == &quot;SOX17&quot;) + 3, which(clusterresults[2, ] == 1)] and D[which(genenames == &quot;SOX17&quot;) + 3, which(clusterresults[2, ] == 3)]
## t = 15.502, df = 240.45, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.957837 2.527851
## sample estimates:
##  mean of x  mean of y 
## 2.32168271 0.07883878</code></pre>
<p>Typically we won’t always know the important genes, but can perform an unbiased analysis by testing all genes.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">pvalstore &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">mode=</span><span class="st">&quot;numeric&quot;</span>, <span class="dt">length=</span><span class="kw">length</span>(genenames))</a>
<a class="sourceLine" id="cb26-2" data-line-number="2"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(genenames))){</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">pvals &lt;-<span class="st"> </span><span class="kw">t.test</span>(D[<span class="kw">which</span>(genenames<span class="op">==</span>genenames[i])<span class="op">+</span><span class="dv">3</span>, <span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">1</span>)],D[<span class="kw">which</span>(genenames<span class="op">==</span>genenames[i])<span class="op">+</span><span class="dv">3</span>, <span class="kw">which</span>(clusterresults[<span class="dv">2</span>,]<span class="op">==</span><span class="dv">3</span>)])</a>
<a class="sourceLine" id="cb26-4" data-line-number="4">pvalstore[i]  &lt;-<span class="st">  </span>pvals<span class="op">$</span>p.value</a>
<a class="sourceLine" id="cb26-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb26-6" data-line-number="6">sortedgenes &lt;-<span class="st"> </span>genenames[<span class="kw">order</span>(pvalstore)]</a></code></pre></div>
<p>Within our example, the original axes of our data have very obvious solutions: the axes represent the expression levels of individual genes. The PCs, however, represent linear combinations of various genes, and do not have obvious interpretations. To find an intuition, we can project the original axes (genes) into the new co-ordinate system. This is stored in \texttt{pcaresult$rotation} variable.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="kw">plot</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw">text</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], genenames, <span class="dt">cex =</span> <span class="fl">.4</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Okay, this plot is a little busy, so let’s focus in on a particular region. Recall that PGCs seemed to lie towards the upper section of the plot (that is PC2 separated out PGCs from other cell types), so we’ll take a look at the top section:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="kw">plot</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;n&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.07</span>, <span class="fl">0.07</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="fl">0.04</span>, <span class="fl">0.1</span>))</a>
<a class="sourceLine" id="cb28-2" data-line-number="2">genenames &lt;-<span class="st"> </span><span class="kw">rownames</span>(D)</a>
<a class="sourceLine" id="cb28-3" data-line-number="3">genenames &lt;-<span class="st"> </span>genenames[<span class="dv">4</span><span class="op">:</span><span class="kw">nrow</span>(D)]</a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="kw">text</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], genenames, <span class="dt">cex =</span> <span class="fl">.4</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>We now see a number of genes that are potentially associated with PGCs. These include a number of known PGCs, for example, both SOX17 and PRDM1 (which can be found at co-ordinates PC1=0, PC2= 0.04) represent two key specifiers of human PGC fate <span class="citation">(Irie et al. <a href="#ref-irie2015sox17">2015</a>,<span class="citation">@tang2015unique</span>,<span class="citation">@kobayashi2017principles</span>)</span>. We further note a number of other key regulators, such as DAZL, have been implicated in germ cell development, with DAZL over expressed ESCs forming spermatogonia-like colonies in a rare instance upon xenotransplantation <span class="citation">(Panula et al. <a href="#ref-panula2016over">2016</a>)</span>.</p>
<p>We can similarly look at regions associated with early embryogenesis by concentrating on the lower half of the plot:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">plot</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;n&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="fl">0.0</span>, <span class="fl">0.07</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.07</span>, <span class="fl">-0.03</span>))</a>
<a class="sourceLine" id="cb29-2" data-line-number="2">genenames &lt;-<span class="st"> </span><span class="kw">rownames</span>(D)</a>
<a class="sourceLine" id="cb29-3" data-line-number="3">genenames &lt;-<span class="st"> </span>genenames[<span class="dv">4</span><span class="op">:</span><span class="kw">nrow</span>(D)]</a>
<a class="sourceLine" id="cb29-4" data-line-number="4"><span class="kw">text</span>(pcaresult<span class="op">$</span>rotation[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], genenames, <span class="dt">cex =</span> <span class="fl">.4</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>This appears to identify a number of genes associated with embryogenesis, for example, DPPA3, which encodes for a maternally inherited factor, Stella, required for normal pre-implantation development <span class="citation">(Bortvin et al. <a href="#ref-bortvin2004dppa3">2004</a>,<span class="citation">@payer2003stella</span>)</span> as well as regulation of transcriptional and endogenous retrovirus programs during maternal-to-zygotic transition <span class="citation">(Huang et al. <a href="#ref-Huang2017stella">2017</a>)</span>.</p>
</div>
<div id="nonlinear-dimensionality-reduction" class="section level2">
<h2><span class="header-section-number">3.3</span> Nonlinear Dimensionality Reduction</h2>
<p>Whilst <span id="linear-dimensionality-reduction">PCA</span> is extremely useful for exploratory analysis, it is not always appropriate, particularly for datasets with nonlinearities. A large number of nonlinear dimensionality reduction techniques have therefore been developed. Perhaps the most commonly applied technique of the moment is t-distributed stochastic neighbour embedding (tSNE) <span class="citation">(Maaten and Hinton <a href="#ref-maaten2008visualizing">2008</a>,<span class="citation">@van2009learning</span>,<span class="citation">@van2012visualizing</span>,<span class="citation">@van2014accelerating</span>)</span>.</p>
<p>In general, tSNE attempts to take points in a high-dimensional space and find a faithful representation of those points in a lower-dimensional space. The SNE algorithm initially converts the high-dimensional Euclidean distances between datapoints into conditional probabilities. Here <span class="math inline">\(p_{j|i}\)</span>, indicates the probability that datapoint <span class="math inline">\(x_i\)</span> would pick <span class="math inline">\(x_j\)</span> as its neighbour if neighbours were picked in proportion to their probability density under a Gaussian centred at <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math inline">\(p_{j|i} = \frac{\exp(-|\mathbf{x}_i - \mathbf{x}_j|^2/2\sigma_i^2)}{\sum_{k\neq l}\exp(-|\mathbf{x}_k - \mathbf{x}_l|^2/2\sigma_i^2)}\)</span></p>
<p>We can define a similar conditional probability for the datapoints in the reduced dimensional space, <span class="math inline">\(y_j\)</span> and <span class="math inline">\(y_j\)</span> as:</p>
<p><span class="math inline">\(q_{j|i} = \frac{\exp(-|\mathbf{y}_i - \mathbf{y}_j|^2)}{\sum_{k\neq l}\exp(-|\mathbf{y}_k - \mathbf{y}_l|^2)}\)</span>.</p>
<p>Natural extensions to this would instead use a Student-t distribution for the lower dimensional space:</p>
<p><span class="math inline">\(q_{j|i} = \frac{(1+|\mathbf{y}_i - \mathbf{y}_j|^2)^{-1}}{\sum_{k\neq l}(1+|\mathbf{y}_i - \mathbf{y}_j|^2)^{-1}}\)</span>.</p>
<p>If SNE has mapped points <span class="math inline">\(\mathbf{y}_i\)</span> and <span class="math inline">\(\mathbf{y}_j\)</span> faithfully, we have <span class="math inline">\(p_{j|i} = q_{j|i}\)</span>. We can define a similarity measure over these distribution based on the Kullback-Leibler-divergence:</p>
<p><span class="math inline">\(C = \sum KL(P_i||Q_i)= \sum_i \sum_j p_{i|j} \log \biggl{(} \frac{p_{i|j}}{q_{i|j}} \biggr{)}\)</span></p>
<p>If <span class="math inline">\(p_{j|i} = q_{j|i}\)</span>, that is, if our reduced dimensionality representation faithfully captures the higher dimensional data, this value will be equal to zero, otherwise it will be a positive number. We can attempt to minimise this value using gradient descent.</p>
<p>Note that in many cases this lower dimensionality space can be initialised using PCA or other dimensionality reduction technique. The tSNE algorithm is implemented in R via the  package.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">library</span>(Rtsne)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2"><span class="kw">library</span>(scatterplot3d)</a>
<a class="sourceLine" id="cb30-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">12345</span>)</a></code></pre></div>
<p>To get a feel for tSNE we will first generate some artificial data. In this case we generate two different groups that exist in a 3-dimensional space. We choose these groups to be Gaussian distributed, with different means and variances:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">D1 &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">rnorm</span>(<span class="dv">5</span><span class="op">*</span><span class="dv">3</span>,<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span><span class="dv">1</span>), <span class="dv">100</span>, <span class="dv">3</span>) </a>
<a class="sourceLine" id="cb31-2" data-line-number="2">D2 &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">rnorm</span>(<span class="dv">5</span><span class="op">*</span><span class="dv">3</span>,<span class="dt">mean=</span><span class="dv">5</span>,<span class="dt">sd=</span><span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">3</span>) </a>
<a class="sourceLine" id="cb31-3" data-line-number="3">G1 &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1</span>) </a>
<a class="sourceLine" id="cb31-4" data-line-number="4">G2 &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="dv">2</span>, <span class="dv">100</span>, <span class="dv">1</span>) </a>
<a class="sourceLine" id="cb31-5" data-line-number="5">D3 &lt;-<span class="st"> </span><span class="kw">rbind</span>(D1,D2)</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">G3 &lt;-<span class="st"> </span><span class="kw">rbind</span>(G1,G2)</a>
<a class="sourceLine" id="cb31-7" data-line-number="7">colors &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb31-8" data-line-number="8">colors &lt;-<span class="st"> </span>colors[G3]</a>
<a class="sourceLine" id="cb31-9" data-line-number="9"><span class="kw">scatterplot3d</span>(D3,<span class="dt">color=</span>colors, <span class="dt">main=</span><span class="st">&quot;3D Scatterplot&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,<span class="dt">zlab=</span><span class="st">&quot;z&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>We can run tSNE on this dataset and try to condense the data down from a three-dimensional to a two-dimensional representation. Unlike PCA, which has no real free parameters, tSNE has a variety of parameters that need to be set. First, we have the perplexity parameter which, in essence, balances local and global aspects of the data. For low values of perplexity, the algorithm will tend to entirely focus on keeping datapoints locally together.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">tsne_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">Rtsne</span>(<span class="kw">as.matrix</span>(D3), <span class="dt">check_duplicates=</span><span class="ot">FALSE</span>, <span class="dt">pca=</span><span class="ot">TRUE</span>, <span class="dt">perplexity=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="fl">0.5</span>, <span class="dt">dims=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2">y1 &lt;-<span class="st"> </span>tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==-</span><span class="dv">1</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</a>
<a class="sourceLine" id="cb32-3" data-line-number="3">tsne_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">Rtsne</span>(<span class="kw">as.matrix</span>(D3), <span class="dt">check_duplicates=</span><span class="ot">FALSE</span>, <span class="dt">pca=</span><span class="ot">TRUE</span>, <span class="dt">perplexity=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="fl">0.5</span>, <span class="dt">dims=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb32-4" data-line-number="4"></a>
<a class="sourceLine" id="cb32-5" data-line-number="5"><span class="kw">plot</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">xlab=</span><span class="st">&quot;tSNE1&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;tSNE1&quot;</span>)</a>
<a class="sourceLine" id="cb32-6" data-line-number="6"><span class="kw">points</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">101</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Note that here we have set the perplexity parameter reasonably low, and tSNE appears to have identified a lot of local structure that (we know) doesn’t exist. Let’s try again using a larger value for the perplexity parameter.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">y1 &lt;-<span class="st"> </span>tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="kw">which</span>(D[<span class="dv">1</span>,]<span class="op">==-</span><span class="dv">1</span>),<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</a>
<a class="sourceLine" id="cb33-2" data-line-number="2">tsne_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">Rtsne</span>(<span class="kw">as.matrix</span>(D3), <span class="dt">check_duplicates=</span><span class="ot">FALSE</span>, <span class="dt">pca=</span><span class="ot">TRUE</span>, <span class="dt">perplexity=</span><span class="dv">50</span>, <span class="dt">theta=</span><span class="fl">0.5</span>, <span class="dt">dims=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb33-3" data-line-number="3"></a>
<a class="sourceLine" id="cb33-4" data-line-number="4"><span class="kw">plot</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">xlab=</span><span class="st">&quot;tSNE1&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;tSNE2&quot;</span>)</a>
<a class="sourceLine" id="cb33-5" data-line-number="5"><span class="kw">points</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">101</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>This appears to have done a better job of representing the data in a two-dimensional space.
### Nonlinear warping</p>
<p>In our previous example we showed that if the perplexity parameter was correctly set, tSNE seperated out the two populations very well. If we plot the original data next to the tSNE reduced dimensionality represention, however, we will notice something interesting:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="kw">scatterplot3d</span>(D3,<span class="dt">color=</span>colors, <span class="dt">main=</span><span class="st">&quot;3D Scatterplot&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,<span class="dt">zlab=</span><span class="st">&quot;z&quot;</span>)</a>
<a class="sourceLine" id="cb34-3" data-line-number="3"><span class="kw">plot</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">xlab=</span><span class="st">&quot;tSNE1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;tSNE2&quot;</span>)</a>
<a class="sourceLine" id="cb34-4" data-line-number="4"><span class="kw">points</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">101</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Whilst in the origianl data the two groups had very different variances, in the reduced dimensionality representation they appeared to show a similar spread. This is down to tSNEs ability to represent nonlinearities, and the algorithm performs different transformations on different regions. This is important to keep in mind: the spread in a tSNE output are not always indicative of the level of heterogeneity in the data.</p>
<div id="stochasticity" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Stochasticity</h3>
<p>A final important point to note is that tSNE is stochastic in nature. Unlike PCA which, for the same dataset, will always yield the same result, if you run tSNE twice you will likely find different results. We can illustrate this below, by running tSNE again for perplexity <span class="math inline">\(30\)</span>, and plotting the results alongside the previous ones.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">123456</span>)</a>
<a class="sourceLine" id="cb35-2" data-line-number="2"></a>
<a class="sourceLine" id="cb35-3" data-line-number="3">tsne_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">Rtsne</span>(<span class="kw">as.matrix</span>(D3), <span class="dt">check_duplicates=</span><span class="ot">FALSE</span>, <span class="dt">pca=</span><span class="ot">TRUE</span>, <span class="dt">perplexity=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="fl">0.5</span>, <span class="dt">dims=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb35-4" data-line-number="4"></a>
<a class="sourceLine" id="cb35-5" data-line-number="5">tsne_model_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">Rtsne</span>(<span class="kw">as.matrix</span>(D3), <span class="dt">check_duplicates=</span><span class="ot">FALSE</span>, <span class="dt">pca=</span><span class="ot">TRUE</span>, <span class="dt">perplexity=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="fl">0.5</span>, <span class="dt">dims=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb35-6" data-line-number="6"></a>
<a class="sourceLine" id="cb35-7" data-line-number="7"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb35-8" data-line-number="8"><span class="kw">plot</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">xlab=</span><span class="st">&quot;tSNE1&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;tSNE2&quot;</span>)</a>
<a class="sourceLine" id="cb35-9" data-line-number="9"><span class="kw">points</span>(tsne_model_<span class="dv">1</span><span class="op">$</span>Y[<span class="dv">101</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb35-10" data-line-number="10"></a>
<a class="sourceLine" id="cb35-11" data-line-number="11"><span class="kw">plot</span>(tsne_model_<span class="dv">2</span><span class="op">$</span>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">45</span>),<span class="dt">xlab=</span><span class="st">&quot;tSNE1&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;tSNE2&quot;</span>)</a>
<a class="sourceLine" id="cb35-12" data-line-number="12"><span class="kw">points</span>(tsne_model_<span class="dv">2</span><span class="op">$</span>Y[<span class="dv">101</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">type=</span><span class="st">&quot;p&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="02-dimensionality-reduction_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Note that this stochasticity, itself, may be a useful property, allowing us to gauge robustness of our biological interpretations. A comprehensive blog discussing the various pitfalls of tSNE is available <a href="https://distill.pub/2016/misread-tsne/">here</a>.</p>
</div>
<div id="analysis-of-mammalian-development" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Analysis of mammalian development</h3>
<p>In earlier sections we used PCA to analyse scRNA-seq datasets of early human embryo development. In general PCA seemed adept at picking out different cell types and idetifying putative regulators associated with those cell types. We will now use tSNE to analyse the same data.</p>
<p>Excercise 2.5. Load in the single cell dataset and run tSNE. How do pre-implantation cells look in tSNE?</p>
<p>Excercise 2.6. Note that cells labelled as pre-implantation actually consists of a variety of cells, from oocytes through to blastocyst stage. Take a look at the pre-implantation cells only using tSNE. Hint: a more refined categorisation of the developmental stage of pre-implantation cells can be found by looking at the developmental time variable (0=oocyte, 1=zygote, 2=2C, 3=4C, 4=8C, 5=Morula, 6=blastocyst). Try plotting the data from tSNE colouring the data according to developmental stage.</p>
</div>
</div>
<div id="other-dimensionality-reduction-techniques" class="section level2">
<h2><span class="header-section-number">3.4</span> Other dimensionality reduction techniques</h2>
<p>A large number of alternative dimensionality reduction techniques exist with corresponding implementation in R. These include probabilistic extensions to PCA <a href="https://www.rdocumentation.org/packages/pcaMethods/versions/1.64.0">pcaMethods</a>, as well as other nonlinear dimensionality reduction techniques <a href="https://www.rdocumentation.org/packages/RDRToolbox/versions/1.22.0">Isomap</a>, as well as those based on Gaussian Processes (<a href="https://github.com/SheffieldML/vargplvm.git">GPLVM</a>; Lawrence 2004). Other packages such as <a href="https://cran.r-project.org/web/packages/kernlab/index.html">kernlab</a> provide a general suite of tools for dimensionality reduction.</p>
<p>Solutions to exercises can be found in appendix <a href="solutions-dimensionality-reduction.html#solutions-dimensionality-reduction">B</a>.</p>

</div>
</div>
<h3><span class="header-section-number">K</span> Solutions for use case 2</h3>
<div id="refs" class="references">
<div id="ref-bortvin2004dppa3">
<p>Bortvin, Alex, Mary Goodheart, Michelle Liao, and David C Page. 2004. “Dppa3/Pgc7/Stella Is a Maternal Factor and Is Not Required for Germ Cell Specification in Mice.” <em>BMC Developmental Biology</em> 4 (1). BioMed Central: 2.</p>
</div>
<div id="ref-Breeze873">
<p>Breeze, Emily, Elizabeth Harrison, Stuart McHattie, Linda Hughes, Richard Hickman, Claire Hill, Steven Kiddle, et al. 2011. “High-Resolution Temporal Profiling of Transcripts During Arabidopsis Leaf Senescence Reveals a Distinct Chronology of Processes and Regulation.” <em>The Plant Cell Online</em> 23 (3). American Society of Plant Biologists: 873–94. <a href="https://doi.org/10.1105/tpc.111.083345">https://doi.org/10.1105/tpc.111.083345</a>.</p>
</div>
<div id="ref-guo2015transcriptome">
<p>Guo, Fan, Liying Yan, Hongshan Guo, Lin Li, Boqiang Hu, Yangyu Zhao, Jun Yong, et al. 2015. “The Transcriptome and DNA Methylome Landscapes of Human Primordial Germ Cells.” <em>Cell</em> 161 (6). Elsevier: 1437–52.</p>
</div>
<div id="ref-hotelling1933analysis">
<p>Hotelling, Harold. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” <em>Journal of Educational Psychology</em> 24 (6). Warwick &amp; York: 417.</p>
</div>
<div id="ref-Huang2017stella">
<p>Huang, Yun, Kyoung Kim Jong, Dang V Do, Caroline Lee, Christopher A. Penfold, Jan J Zylicz, John C. Marioni, Jamie A. Hackett, and M. Azim Surani. 2017. “Stella Controls Transcriptional and Endogenous Retrovirus Programmes During Maternal-to-Zygotic Transition.” <em>eLife</em> 1 (1). eLife: 1.</p>
</div>
<div id="ref-irie2015sox17">
<p>Irie, Naoko, Leehee Weinberger, Walfred WC Tang, Toshihiro Kobayashi, Sergey Viukov, Yair S Manor, Sabine Dietmann, Jacob H Hanna, and M Azim Surani. 2015. “SOX17 Is a Critical Specifier of Human Primordial Germ Cell Fate.” <em>Cell</em> 160 (1). Elsevier: 253–68.</p>
</div>
<div id="ref-maaten2008visualizing">
<p>Maaten, Laurens van der, and Geoffrey Hinton. 2008. “Visualizing Data Using T-Sne.” <em>Journal of Machine Learning Research</em> 9 (Nov): 2579–2605.</p>
</div>
<div id="ref-novembre2008interpreting">
<p>Novembre, John, and Matthew Stephens. 2008. “Interpreting Principal Component Analyses of Spatial Population Genetic Variation.” <em>Nature Genetics</em> 40 (5). Nature Publishing Group: 646–49.</p>
</div>
<div id="ref-panula2016over">
<p>Panula, Sarita, Ahmed Reda, Jan-Bernd Stukenborg, Cyril Ramathal, Meena Sukhwani, Halima Albalushi, Daniel Edsgärd, et al. 2016. “Over Expression of Nanos3 and Dazl in Human Embryonic Stem Cells.” <em>PloS One</em> 11 (10). Public Library of Science: e0165268.</p>
</div>
<div id="ref-pearson1901liii">
<p>Pearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 2 (11). Taylor &amp; Francis: 559–72.</p>
</div>
<div id="ref-ringner2008principal">
<p>Ringnér, Markus. 2008. “What Is Principal Component Analysis?” <em>Nature Biotechnology</em> 26 (3). Nature Publishing Group: 303–4.</p>
</div>
<div id="ref-saal2007poor">
<p>Saal, Lao H, Peter Johansson, Karolina Holm, Sofia K Gruvberger-Saal, Qing-Bai She, Matthew Maurer, Susan Koujak, et al. 2007. “Poor Prognosis in Carcinoma Is Associated with a Gene Expression Signature of Aberrant Pten Tumor Suppressor Pathway Activity.” <em>Proceedings of the National Academy of Sciences</em> 104 (18). National Acad Sciences: 7564–9.</p>
</div>
<div id="ref-sforza1964analysis">
<p>Sforza, Cavalli LL, and Anthony William Fairbank Edwards. 1964. “Analysis of Human Evolution.” <em>Genet. Today</em> 3: 923–33.</p>
</div>
<div id="ref-svensson2017moore">
<p>Svensson, Valentine, Roser Vento-Tormo, and Sarah A Teichmann. 2017. “Moore’s Law in Single Cell Transcriptomics.” <em>arXiv Preprint arXiv:1704.01379</em>.</p>
</div>
<div id="ref-tang2009mrna">
<p>Tang, Fuchou, Catalin Barbacioru, Yangzhou Wang, Ellen Nordman, Clarence Lee, Nanlan Xu, Xiaohui Wang, et al. 2009. “MRNA-Seq Whole-Transcriptome Analysis of a Single Cell.” <em>Nature Methods</em> 6 (5). Nature Publishing Group: 377–82.</p>
</div>
<div id="ref-vohradsky1997identification">
<p>Vohradsky, Jiřı', Xin-Ming Li, and Charles J Thompson. 1997. “Identification of Procaryotic Developmental Stages by Statistical Analyses of Two-Dimensional Gel Patterns.” <em>Electrophoresis</em> 18 (8). Wiley Online Library: 1418–28.</p>
</div>
<div id="ref-yan2013single">
<p>Yan, Liying, Mingyu Yang, Hongshan Guo, Lu Yang, Jun Wu, Rong Li, Ping Liu, et al. 2013. “Single-Cell RNA-Seq Profiling of Human Preimplantation Embryos and Embryonic Stem Cells.” <em>Nature Structural &amp; Molecular Biology</em> 20 (9). Nature Publishing Group: 1131–9.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
