<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>caret</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
  body {
    padding: 2cm; 
  }
}
</style>


</head>

<body>

<hr>

<p>output:
  html_document: default</p>

<h2 id="toc_0">  pdf_document: default</h2>

<h1 id="toc_1">An introduction to caret</h1>

<p>author:
date:
autosize: true
transition: rotate
css: custom.css</p>

<h1 id="toc_2">Machine Learning libraries</h1>

<ul>
<li>No need to implement your own machine learning models</li>
<li>High-level abstractions available: SciKitLearn, Theano, TensorFlow, Spark</li>
<li>Different languages and platforms supported, e.g. CPU, GPU, TPU, Hadoop</li>
<li>Adoption of R for data science has outpaced others in recent years</li>
</ul>

<h1 id="toc_3">Caret package for R</h1>

<p>The caret package was developed by Max Kuhn to:</p>

<ul>
<li>create a unified interface for modeling and prediction (interfaces to over 200 models)</li>
<li>streamline model tuning using cross-validation and resampling</li>
<li>simplify preprocessing and transformation of the data</li>
<li>provide a variety of “helper” functions and classes for day–to–day model building tasks</li>
<li>increase computational efficiency using parallel processing</li>
</ul>

<p><a href="https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf">https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf</a></p>

<h1 id="toc_4">Book: Applied Predictive Modelling</h1>

<ul>
<li>Statistics deals with &#39;inference&#39;, ML deals with &#39;prediction&#39;</li>
<li>Statistics involves confidence intervals, p-values etc </li>
<li>The best inferential model is not necessarily the most predictive</li>
<li>Examples of ML are spam detection, sentiment analysis, etc</li>
<li>Prediction &#39;accuracy&#39; rules; model &#39;interpretability&#39; is secondary</li>
</ul>

<p>Biology is a good setting for ML, as mechanics of model shouldn&#39;t matter if mechanism of disease is unknown</p>

<h1 id="toc_5">Cross validation:</h1>

<ul>
<li>CV is central to tuning the model parameters</li>
<li>Data is divided into training and test sets</li>
<li>Use the Training set to &#39;build&#39; the model</li>
<li>Use the Test set to &#39;validate&#39; the model</li>
</ul>

<p>5-fold CV:</p>

<ul>
<li>Divide the Training set into 5 equally sized partitions</li>
<li>Use one of the partitions for validation and the rest for training</li>
<li>&#39;Repeated&#39; CV uses resampling to take different looks at the data</li>
</ul>

<h1 id="toc_6">Cross validation (II):</h1>

<ul>
<li>Best estimates for model parameters are obtained by optimisation of an objective (cost) function</li>
<li>Examples of objective functions: classification accuracy, regression RMSE </li>
<li>Optimisation is usually by gradient decent, or information-theoretic optimisation for tree-based models, or back-propagation for deep neural networks, etc</li>
<li>Cross-validation accuracy is calculated by averaging across all the resamplings</li>
<li>&#39;Prediction accuracy&#39; is obtained by applying the fitted model to held-out Test data</li>
</ul>

<h1 id="toc_7">Why we need caret</h1>

<table>
<thead>
<tr>
<th style="text-align: left">obj Class</th>
<th style="text-align: left">Package</th>
<th style="text-align: left">predict Function Syntax</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: left">lda</td>
<td style="text-align: left">MASS</td>
<td style="text-align: left">predict(obj) (no options needed)</td>
</tr>
<tr>
<td style="text-align: left">glm</td>
<td style="text-align: left">stats</td>
<td style="text-align: left">predict(obj, type = &quot;response&quot;)</td>
</tr>
<tr>
<td style="text-align: left">gbm</td>
<td style="text-align: left">gbm</td>
<td style="text-align: left">predict(obj, type = &quot;response&quot;, n.trees)</td>
</tr>
<tr>
<td style="text-align: left">mda</td>
<td style="text-align: left">mda</td>
<td style="text-align: left">predict(obj, type = &quot;posterior&quot;)</td>
</tr>
<tr>
<td style="text-align: left">rpart</td>
<td style="text-align: left">rpart</td>
<td style="text-align: left">predict(obj, type = &quot;prob&quot;)</td>
</tr>
<tr>
<td style="text-align: left">Weka</td>
<td style="text-align: left">RWeka</td>
<td style="text-align: left">predict(obj, type = &quot;probability&quot;)</td>
</tr>
<tr>
<td style="text-align: left">LogitBoost</td>
<td style="text-align: left">caTools</td>
<td style="text-align: left">predict(obj, type = &quot;raw&quot;, nIter)</td>
</tr>
</tbody>
</table>

<p>https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user<em>caret</em>2up.pdf</p>

<h1 id="toc_8">Available Models</h1>

<p><a href="https://topepo.github.io/caret/available-models.html">https://topepo.github.io/caret/available-models.html</a></p>

<h1 id="toc_9">CARET Workflow</h1>

<p>type:section</p>

<h1 id="toc_10">CARET Workflow</h1>

<ul>
<li>required packages</li>
<li>example data set</li>
<li>partition data</li>
<li>assess data quality</li>
<li>model training and parameter tuning</li>
<li>model comparison</li>
<li>predict test set</li>
</ul>

<h1 id="toc_11">Packages</h1>

<p>Load <strong>CARET</strong> package</p>

<div><pre><code class="language-r">library(caret)</code></pre></div>

<p>Other required packages are <strong>doMC</strong> (parallel processing) and <strong>corrplot</strong> (correlation matrix plots):</p>

<div><pre><code class="language-r">library(doMC)
library(corrplot)</code></pre></div>

<h1 id="toc_12">Example data set</h1>

<p>type:section</p>

<h1 id="toc_13">Wheat seeds data set</h1>

<p>The seeds data set https://archive.ics.uci.edu/ml/datasets/seeds contains morphological measurements on the kernels of three varieties of wheat: Kama, Rosa and Canadian.</p>

<p>Load the data into your R session using:</p>

<div><pre><code class="language-r">load(&quot;data/wheat_seeds/wheat_seeds.Rda&quot;)</code></pre></div>

<p>What objects have been loaded into our R session?</p>

<div><pre><code class="language-r">ls()</code></pre></div>

<div><pre><code class="language-none">[1] &quot;morphometrics&quot; &quot;variety&quot;      </code></pre></div>

<h1 id="toc_14">Wheat seeds data set: predictors</h1>

<p>The <strong>morphometrics</strong> data.frame contains seven variables describing the morphology of the seeds.</p>

<div><pre><code class="language-r">str(morphometrics)</code></pre></div>

<div><pre><code class="language-none">&#39;data.frame&#39;:   210 obs. of  7 variables:
 $ area        : num  15.3 14.9 14.3 13.8 16.1 ...
 $ perimeter   : num  14.8 14.6 14.1 13.9 15 ...
 $ compactness : num  0.871 0.881 0.905 0.895 0.903 ...
 $ kernLength  : num  5.76 5.55 5.29 5.32 5.66 ...
 $ kernWidth   : num  3.31 3.33 3.34 3.38 3.56 ...
 $ asymCoef    : num  2.22 1.02 2.7 2.26 1.35 ...
 $ grooveLength: num  5.22 4.96 4.83 4.8 5.17 ...</code></pre></div>

<h1 id="toc_15">Wheat seeds data set: class labels</h1>

<p>The class labels of the seeds are in the factor <strong>variety</strong>.</p>

<div><pre><code class="language-r">summary(variety)</code></pre></div>

<div><pre><code class="language-none">Canadian     Kama     Rosa 
      70       70       70 </code></pre></div>

<h1 id="toc_16">Partition data</h1>

<p>type:section</p>

<h1 id="toc_17">Training and test set</h1>

<p><img src="img/cross-validation.png" alt=""></p>

<h1 id="toc_18">Partition data into training and test set</h1>

<div><pre><code class="language-r">set.seed(42)
trainIndex &lt;- createDataPartition(y=variety, times=1, p=0.7, list=F)

varietyTrain &lt;- variety[trainIndex]
morphTrain &lt;- morphometrics[trainIndex,]

varietyTest &lt;- variety[-trainIndex]
morphTest &lt;- morphometrics[-trainIndex,]</code></pre></div>

<h1 id="toc_19">Class distributions are balanced across the splits</h1>

<p>Training set</p>

<div><pre><code class="language-r">summary(varietyTrain)</code></pre></div>

<div><pre><code class="language-none">Canadian     Kama     Rosa 
      49       49       49 </code></pre></div>

<p>Test set</p>

<div><pre><code class="language-r">summary(varietyTest)</code></pre></div>

<div><pre><code class="language-none">Canadian     Kama     Rosa 
      21       21       21 </code></pre></div>

<h1 id="toc_20">Assess data quality</h1>

<p>type:section</p>

<h1 id="toc_21">Identification of near zero variance predictors</h1>

<p>The function <strong>nearZeroVar</strong> identifies predictors that have one unique value. It also diagnoses predictors having both of the following characteristics:</p>

<ul>
<li>very few unique values relative to the number of samples</li>
<li>the ratio of the frequency of the most common value to the frequency of the 2nd most common value is large.</li>
</ul>

<p>Such zero and near zero-variance predictors have a deleterious impact on modelling and may lead to unstable fits.</p>

<h1 id="toc_22">Identification of near zero variance predictors cont.</h1>

<div><pre><code class="language-r">nearZeroVar(morphTrain, saveMetrics = T)</code></pre></div>

<div><pre><code class="language-none">             freqRatio percentUnique zeroVar   nzv
area               1.5      93.87755   FALSE FALSE
perimeter          1.0      85.03401   FALSE FALSE
compactness        1.0      93.19728   FALSE FALSE
kernLength         1.5      91.83673   FALSE FALSE
kernWidth          1.5      91.15646   FALSE FALSE
asymCoef           1.0      98.63946   FALSE FALSE
grooveLength       1.0      77.55102   FALSE FALSE</code></pre></div>

<h1 id="toc_23">Are all predictors on the same scale?</h1>

<div><pre><code class="language-r">featurePlot(x = morphTrain,
            y = varietyTrain,
            plot = &quot;box&quot;,
            ## Pass in options to bwplot()
            scales = list(y = list(relation=&quot;free&quot;),
                          x = list(rot = 90)),
            layout = c(4,2))</code></pre></div>

<h1 id="toc_24">Feature plots</h1>

<p><img src="caret-figure/unnamed-chunk-15-1.png" title="plot of chunk unnamed-chunk-15" alt="plot of chunk unnamed-chunk-15" width="100%" style="display: block; margin: auto;" /></p>

<h1 id="toc_25">Predictors on different scales</h1>

<p>The variables in this data set are on different scales. In this situation it is important to <strong>centre</strong> and <strong>scale</strong> each predictor.</p>

<ul>
<li>A predictor variable is <strong>centered</strong> by subtracting the mean of the predictor from each value.</li>
<li>To <strong>scale</strong> a predictor variable, each value is divided by its standard deviation.</li>
</ul>

<p>After centring and scaling the predictor variable has a mean of 0 and a standard deviation of 1.</p>

<h1 id="toc_26">Pairwise correlation between predictors</h1>

<p>Examine pairwise correlations of predictors to identify redundancy in data set</p>

<div><pre><code class="language-r">corMat &lt;- cor(morphTrain)
corrplot(corMat, order=&quot;hclust&quot;, tl.cex=1)</code></pre></div>

<h1 id="toc_27">Pairwise correlation between predictors cont.</h1>

<p><img src="caret-figure/unnamed-chunk-17-1.png" title="plot of chunk unnamed-chunk-17" alt="plot of chunk unnamed-chunk-17" width="100%" style="display: block; margin: auto;" /></p>

<h1 id="toc_28">Find highly correlated predictors</h1>

<div><pre><code class="language-r">highCorr &lt;- findCorrelation(corMat, cutoff=0.75)
length(highCorr)</code></pre></div>

<div><pre><code class="language-none">[1] 4</code></pre></div>

<div><pre><code class="language-r">names(morphTrain)[highCorr]</code></pre></div>

<div><pre><code class="language-none">[1] &quot;area&quot;       &quot;kernWidth&quot;  &quot;perimeter&quot;  &quot;kernLength&quot;</code></pre></div>

<h1 id="toc_29">Model training and parameter tuning</h1>

<p>type: section</p>

<h1 id="toc_30">Models to evaluate</h1>

<ul>
<li><strong>svmRadialCost</strong> with one tuning parameter <strong>C</strong></li>
<li><strong>svmRadialSigma</strong> with two tuning parameters: <strong>sigma</strong> and <strong>C</strong></li>
</ul>

<p>To find out more information about a particular model use:</p>

<div><pre><code class="language-r">getModelInfo(&quot;svmRadialSigma&quot;)</code></pre></div>

<h1 id="toc_31">Parameter tuning using cross-validation</h1>

<p><img src="img/cross-validation.png" alt=""></p>

<h1 id="toc_32">Parallel processing</h1>

<p>We will use repeated cross-validation to find the best value of our tuning parameters and we will try 10 values of each.</p>

<p>Repeated cross-validation can readily be parallelized to increase speed of execution. All we need to do is create a local cluster.  <strong>CARET</strong> will then use this cluster to parallelize the cross-validation.</p>

<div><pre><code class="language-r">registerDoMC(detectCores())
getDoParWorkers()</code></pre></div>

<div><pre><code class="language-none">[1] 4</code></pre></div>

<h1 id="toc_33">Resampling</h1>

<p>The resampling method is specified using the <strong>trainControl</strong> function. To repeat five-fold cross validation a total of five times we would use:</p>

<div><pre><code class="language-r">train_ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;,
                           number = 5,
                           repeats = 5)</code></pre></div>

<h1 id="toc_34">Resampling cont.</h1>

<p>To make the analysis reproducible we need to specify the seed for each resampling iteration.</p>

<div><pre><code class="language-r">set.seed(42)
seeds &lt;- vector(mode = &quot;list&quot;, length = 26)
for(i in 1:25) seeds[[i]] &lt;- sample.int(1000, 10)
seeds[[26]] &lt;- sample.int(1000,1)

train_ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;,
                           number = 5,
                           repeats = 5,
                           seeds = seeds)</code></pre></div>

<h1 id="toc_35">Train svmRadialCost model</h1>

<p>The <strong>train</strong> function is used to tune a model</p>

<div><pre><code class="language-r">rcFit &lt;- train(morphTrain, varietyTrain,
                method=&quot;svmRadialCost&quot;,
                preProcess = c(&quot;center&quot;, &quot;scale&quot;),
                #tuneGrid=tuneParam,
                tuneLength=10,
                trControl=train_ctrl)</code></pre></div>

<div><pre><code class="language-r">rcFit</code></pre></div>

<h1 id="toc_36">Train svmRadialCost model cont.</h1>

<div><pre><code class="language-none">Support Vector Machines with Radial Basis Function Kernel 

147 samples
  7 predictor
  3 classes: &#39;Canadian&#39;, &#39;Kama&#39;, &#39;Rosa&#39; 

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 118, 117, 117, 117, 119, 118, ... 
Resampling results across tuning parameters:

  C       Accuracy   Kappa    
    0.25  0.9211790  0.8817025
    0.50  0.9238456  0.8856728
    1.00  0.9278456  0.8916728
    2.00  0.9277997  0.8916162
    4.00  0.9195632  0.8792973
    8.00  0.9182266  0.8772683
   16.00  0.9128506  0.8691940
   32.00  0.9185090  0.8776993
   64.00  0.9089918  0.8634461
  128.00  0.9090837  0.8635816

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was C = 1.</code></pre></div>

<h1 id="toc_37">Train svmRadialCost model cont.</h1>

<p><img src="caret-figure/unnamed-chunk-26-1.png" title="plot of chunk unnamed-chunk-26" alt="plot of chunk unnamed-chunk-26" width="100%" style="display: block; margin: auto;" /></p>

<h1 id="toc_38">Train svmRadialSigma model</h1>

<p>If we set <strong>tuneLength</strong> to 10 the svmRadialSigma model will be evaluated with 10 different values of <strong>C</strong>. The svmRadialSigma model is setup to evaluate a maximum of six values of sigma. Therefore in each resampling iteration we need a total of 60 seeds (10x6).</p>

<div><pre><code class="language-r">set.seed(42)
seeds &lt;- vector(mode = &quot;list&quot;, length = 26)
for(i in 1:25) seeds[[i]] &lt;- sample.int(1000, 60)
seeds[[26]] &lt;- sample.int(1000,1)

train_ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;,
                           number = 5,
                           repeats = 5,
                           seeds = seeds)</code></pre></div>

<h1 id="toc_39">Train svmRadialSigma model cont.</h1>

<p>The <strong>train</strong> function is used to tune a model</p>

<div><pre><code class="language-r">rsFit &lt;- train(morphTrain, varietyTrain,
                method=&quot;svmRadialSigma&quot;,
                preProcess = c(&quot;center&quot;, &quot;scale&quot;),
                #tuneGrid=tuneParam,
                tuneLength=10,
                trControl=train_ctrl)</code></pre></div>

<div><pre><code class="language-r">rsFit</code></pre></div>

<h1 id="toc_40">Train svmRadialSigma model cont.</h1>

<div><pre><code class="language-none">Support Vector Machines with Radial Basis Function Kernel 

147 samples
  7 predictor
  3 classes: &#39;Canadian&#39;, &#39;Kama&#39;, &#39;Rosa&#39; 

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 118, 117, 117, 119, 117, 117, ... 
Resampling results across tuning parameters:

  sigma       C       Accuracy   Kappa    
  0.03298587    0.25  0.9127455  0.8690039
  0.03298587    0.50  0.9139803  0.8707992
  0.03298587    1.00  0.9249787  0.8872711
  0.03298587    2.00  0.9279278  0.8917430
  0.03298587    4.00  0.9320657  0.8979946
  0.03298587    8.00  0.9318325  0.8976274
  0.03298587   16.00  0.9319737  0.8977663
  0.03298587   32.00  0.9399737  0.9097827
  0.03298587   64.00  0.9413071  0.9117827
  0.03298587  128.00  0.9401609  0.9100772
  0.11220186    0.25  0.9275993  0.8912570
  0.11220186    0.50  0.9317833  0.8975240
  0.11220186    1.00  0.9304959  0.8955636
  0.11220186    2.00  0.9415895  0.9122590
  0.11220186    4.00  0.9403021  0.9102937
  0.11220186    8.00  0.9346864  0.9018007
  0.11220186   16.00  0.9305944  0.8956279
  0.11220186   32.00  0.9361182  0.9039525
  0.11220186   64.00  0.9348768  0.9021248
  0.11220186  128.00  0.9305944  0.8956908
  0.19141785    0.25  0.9237865  0.8855445
  0.19141785    0.50  0.9345419  0.9016186
  0.19141785    1.00  0.9388243  0.9081049
  0.19141785    2.00  0.9430640  0.9144600
  0.19141785    4.00  0.9333530  0.8997595
  0.19141785    8.00  0.9263547  0.8892215
  0.19141785   16.00  0.9252611  0.8876242
  0.19141785   32.00  0.9266897  0.8897655
  0.19141785   64.00  0.9211232  0.8814091
  0.19141785  128.00  0.9210739  0.8813310
  0.27063384    0.25  0.9278325  0.8916086
  0.27063384    0.50  0.9331133  0.8994356
  0.27063384    1.00  0.9388276  0.9080804
  0.27063384    2.00  0.9347323  0.9018646
  0.27063384    4.00  0.9304959  0.8954346
  0.27063384    8.00  0.9197833  0.8793671
  0.27063384   16.00  0.9185977  0.8776302
  0.27063384   32.00  0.9157406  0.8733349
  0.27063384   64.00  0.9144072  0.8713351
  0.27063384  128.00  0.9144072  0.8713351
  0.34984983    0.25  0.9277833  0.8914907
  0.34984983    0.50  0.9331133  0.8994356
  0.34984983    1.00  0.9374450  0.9059735
  0.34984983    2.00  0.9346371  0.9017149
  0.34984983    4.00  0.9183547  0.8772711
  0.34984983    8.00  0.9157373  0.8733367
  0.34984983   16.00  0.9185944  0.8776533
  0.34984983   32.00  0.9130246  0.8692947
  0.34984983   64.00  0.9130246  0.8692947
  0.34984983  128.00  0.9130246  0.8692947
  0.42906582    0.25  0.9291166  0.8934907
  0.42906582    0.50  0.9316847  0.8973104
  0.42906582    1.00  0.9360164  0.9038402
  0.42906582    2.00  0.9346371  0.9017313
  0.42906582    4.00  0.9155928  0.8731255
  0.42906582    8.00  0.9144039  0.8713367
  0.42906582   16.00  0.9117865  0.8674486
  0.42906582   32.00  0.9075501  0.8610938
  0.42906582   64.00  0.9075501  0.8610938
  0.42906582  128.00  0.9075501  0.8610938

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were sigma = 0.1914179 and C = 2.</code></pre></div>

<h1 id="toc_41">Train svmRadialSigma model cont.</h1>

<p><img src="caret-figure/unnamed-chunk-31-1.png" title="plot of chunk unnamed-chunk-31" alt="plot of chunk unnamed-chunk-31" width="100%" style="display: block; margin: auto;" /></p>

<h1 id="toc_42">Model comparison</h1>

<p>type:section</p>

<h1 id="toc_43">Make a list of our models</h1>

<div><pre><code class="language-r">model_list &lt;- list(radialCost=rcFit,
                   radialSigma=rsFit)</code></pre></div>

<h1 id="toc_44">Collect resampling results for each model</h1>

<div><pre><code class="language-r">resamps &lt;- resamples(model_list)
resamps</code></pre></div>

<div><pre><code class="language-none">
Call:
resamples.default(x = model_list)

Models: radialCost, radialSigma 
Number of resamples: 25 
Performance metrics: Accuracy, Kappa 
Time estimates for: everything, final model fit </code></pre></div>

<h1 id="toc_45">Summarize resampling results</h1>

<div><pre><code class="language-r">summary(resamps)</code></pre></div>

<div><pre><code class="language-none">
Call:
summary.resamples(object = resamps)

Models: radialCost, radialSigma 
Number of resamples: 25 

Accuracy 
                 Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
radialCost  0.8333333 0.9000000 0.9310345 0.9278456 0.9642857    1    0
radialSigma 0.8620690 0.9285714 0.9333333 0.9430640 0.9666667    1    0

Kappa 
                 Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
radialCost  0.7500000 0.8500000 0.8966132 0.8916728 0.9464627    1    0
radialSigma 0.7913669 0.8923077 0.9000000 0.9144600 0.9500000    1    0</code></pre></div>

<h1 id="toc_46">Plot resampling results</h1>

<div><pre><code class="language-r">bwplot(resamps)</code></pre></div>

<h1 id="toc_47">Boxplots of resampling results</h1>

<p><img src="caret-figure/unnamed-chunk-36-1.png" title="plot of chunk unnamed-chunk-36" alt="plot of chunk unnamed-chunk-36" width="100%" style="display: block; margin: auto;" /></p>

<h1 id="toc_48">Predict test set</h1>

<p>type:section</p>

<h1 id="toc_49">Predict test set</h1>

<p>Predict varieties of the test set using best model.</p>

<div><pre><code class="language-r">test_pred &lt;- predict(rsFit, morphTest)
confusionMatrix(test_pred, varietyTest)</code></pre></div>

<h1 id="toc_50">Confusion matrix</h1>

<div><pre><code class="language-none">Confusion Matrix and Statistics

          Reference
Prediction Canadian Kama Rosa
  Canadian       20    0    0
  Kama            1   20    2
  Rosa            0    1   19

Overall Statistics
                                          
               Accuracy : 0.9365          
                 95% CI : (0.8453, 0.9824)
    No Information Rate : 0.3333          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9048          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: Canadian Class: Kama Class: Rosa
Sensitivity                   0.9524      0.9524      0.9048
Specificity                   1.0000      0.9286      0.9762
Pos Pred Value                1.0000      0.8696      0.9500
Neg Pred Value                0.9767      0.9750      0.9535
Prevalence                    0.3333      0.3333      0.3333
Detection Rate                0.3175      0.3175      0.3016
Detection Prevalence          0.3175      0.3651      0.3175
Balanced Accuracy             0.9762      0.9405      0.9405</code></pre></div>

<h1 id="toc_51">Performance measures</h1>

<p><strong>sensitivity</strong> = TPR = TP/P = TP/(TP+FN)</p>

<p><strong>specificity</strong> = TNR = TN/N = TN/(TN+FP)</p>

<p><strong>precision</strong> = PPV = TP/(TP+FP)</p>

<p><strong>negative predictive value</strong> = TN/(TN+FN)</p>

<h1 id="toc_52">Bias-variance tradeoff</h1>

<p><img src="img/overfitting.png" alt=""></p>

<ul>
<li>Bias is residual error from fitting the Training data</li>
<li>Variance is generalization error when applying the model fit to  Test data
<img src="img/bias-variance.png" alt=""></li>
</ul>

<p>An underfit simple model misses out important features of the data, wheras an overfit complex model fits the noise and outliers.  </p>

<h1 id="toc_53">Resources</h1>

<ul>
<li><p>Manual: http://topepo.github.io/caret/index.html</p></li>
<li><p>JSS Paper: http://www.jstatsoft.org/v28/i05/paper</p></li>
<li><p>Book: http://appliedpredictivemodeling.com</p></li>
</ul>




</body>

</html>
